{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Setup complete. Using torch 2.2.2+cu121 _CudaDeviceProperties(name='NVIDIA GeForce GTX 1650', major=7, minor=5, total_memory=4095MB, multi_processor_count=16)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch veriseti oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    # constructor method img_dir ve data_file adında 2 parametre alıyor\n",
    "    # img_dir -> görüntülerin olduğu dizim\n",
    "    # data_file -> veri dosyasının yolu\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(file=data_file, mode=\"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        # Compose ile belirlenen sırayla ardışık işlemler uygulanır\n",
    "        self.transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                # Görüntü 224x224 piksel olarak yeniden boyutlandırılır\n",
    "                transforms.Resize((224, 224)),\n",
    "                # PIL görüntüsü PyTorch tensörüne dönüştürülür.\n",
    "                # bu dönüşüm piksel değerlerini [0,1] aralığında ölçeklendirir\n",
    "                transforms.ToTensor(),\n",
    "                # Bu dönüşüm, normalleştirme işlemi yapar.\n",
    "                # Her bir kanalı, belirtilen ortalama (mean) ve standart sapma (std) değerlerine göre normalleştirir.\n",
    "                # Bu, genellikle eğitim sürecinde modelin daha hızlı ve daha kararlı öğrenmesine yardımcı olmak için yapılır.\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h, w = img.shape[:2]\n",
    "        # görüntünün yüksekliğini ve genişliğini alır\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR -> RGB\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item[\"kps\"]).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224 / w # x koordinatını yeniden boyutlandırılmış görüntü boyutlarına göre ölçeklendirir\n",
    "        kps[1::2] *= 224 / h # y koordinatını yeniden boyutlandırılmış görüntü boyutlarına göre ölçeklendirir\n",
    "        \n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(\"data/images\", \"data/data_train.json\")\n",
    "val_dataset = KeypointsDataset(\"data/images\", \"data/data_val.json\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "# batch_size -> her parti için 8 veri örneği kullanılarak ilerler\n",
    "# shuffle -> veri seti her epoch başında rastgele karıştırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MyCode\\python-projects\\tennis_analysis\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\MyCode\\python-projects\\tennis_analysis\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "# eğitilmiş ağırlıklara sahip bir ResNet-50 modeli yükler.\n",
    "# pretrained=True -> ImageNet veri kümesinde eğitilmiş ağırlıkları yükler\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14*2)\n",
    "# model.fc -> modelin son katmanını alır\n",
    "# torch.nn.Linear -> tam bağlı bir katman oluşturur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli eğitme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, step 1/829, loss: 9366.7841796875\n",
      "Epoch 1/20, step 11/829, loss: 8609.7060546875\n",
      "Epoch 1/20, step 21/829, loss: 8085.458984375\n",
      "Epoch 1/20, step 31/829, loss: 7765.1376953125\n",
      "Epoch 1/20, step 41/829, loss: 7885.95458984375\n",
      "Epoch 1/20, step 51/829, loss: 7151.0654296875\n",
      "Epoch 1/20, step 61/829, loss: 7205.1552734375\n",
      "Epoch 1/20, step 71/829, loss: 6695.26611328125\n",
      "Epoch 1/20, step 81/829, loss: 6886.0087890625\n",
      "Epoch 1/20, step 91/829, loss: 6157.57958984375\n",
      "Epoch 1/20, step 101/829, loss: 6284.96923828125\n",
      "Epoch 1/20, step 111/829, loss: 5899.2607421875\n",
      "Epoch 1/20, step 121/829, loss: 5890.24072265625\n",
      "Epoch 1/20, step 131/829, loss: 5141.86181640625\n",
      "Epoch 1/20, step 141/829, loss: 5127.859375\n",
      "Epoch 1/20, step 151/829, loss: 4870.6337890625\n",
      "Epoch 1/20, step 161/829, loss: 5002.5390625\n",
      "Epoch 1/20, step 171/829, loss: 4342.29248046875\n",
      "Epoch 1/20, step 181/829, loss: 3816.33935546875\n",
      "Epoch 1/20, step 191/829, loss: 4105.22802734375\n",
      "Epoch 1/20, step 201/829, loss: 3842.332275390625\n",
      "Epoch 1/20, step 211/829, loss: 3896.677001953125\n",
      "Epoch 1/20, step 221/829, loss: 3937.4130859375\n",
      "Epoch 1/20, step 231/829, loss: 3615.852783203125\n",
      "Epoch 1/20, step 241/829, loss: 3075.021240234375\n",
      "Epoch 1/20, step 251/829, loss: 3082.6044921875\n",
      "Epoch 1/20, step 261/829, loss: 2615.97021484375\n",
      "Epoch 1/20, step 271/829, loss: 2526.7451171875\n",
      "Epoch 1/20, step 281/829, loss: 2436.693115234375\n",
      "Epoch 1/20, step 291/829, loss: 2643.4462890625\n",
      "Epoch 1/20, step 301/829, loss: 2311.951904296875\n",
      "Epoch 1/20, step 311/829, loss: 2430.131591796875\n",
      "Epoch 1/20, step 321/829, loss: 1939.3909912109375\n",
      "Epoch 1/20, step 331/829, loss: 1825.0599365234375\n",
      "Epoch 1/20, step 341/829, loss: 1777.031494140625\n",
      "Epoch 1/20, step 351/829, loss: 1837.844482421875\n",
      "Epoch 1/20, step 361/829, loss: 1908.04833984375\n",
      "Epoch 1/20, step 371/829, loss: 1680.2991943359375\n",
      "Epoch 1/20, step 381/829, loss: 1584.5743408203125\n",
      "Epoch 1/20, step 391/829, loss: 1910.787841796875\n",
      "Epoch 1/20, step 401/829, loss: 1455.6092529296875\n",
      "Epoch 1/20, step 411/829, loss: 1361.96142578125\n",
      "Epoch 1/20, step 421/829, loss: 1301.6331787109375\n",
      "Epoch 1/20, step 431/829, loss: 1229.56689453125\n",
      "Epoch 1/20, step 441/829, loss: 1032.335693359375\n",
      "Epoch 1/20, step 451/829, loss: 1014.7799072265625\n",
      "Epoch 1/20, step 461/829, loss: 874.2472534179688\n",
      "Epoch 1/20, step 471/829, loss: 1060.910400390625\n",
      "Epoch 1/20, step 481/829, loss: 836.2003173828125\n",
      "Epoch 1/20, step 491/829, loss: 745.100830078125\n",
      "Epoch 1/20, step 501/829, loss: 722.160888671875\n",
      "Epoch 1/20, step 511/829, loss: 686.5744018554688\n",
      "Epoch 1/20, step 521/829, loss: 672.2811279296875\n",
      "Epoch 1/20, step 531/829, loss: 626.0369873046875\n",
      "Epoch 1/20, step 541/829, loss: 563.5941162109375\n",
      "Epoch 1/20, step 551/829, loss: 560.1900634765625\n",
      "Epoch 1/20, step 561/829, loss: 694.8242797851562\n",
      "Epoch 1/20, step 571/829, loss: 494.199462890625\n",
      "Epoch 1/20, step 581/829, loss: 436.2749328613281\n",
      "Epoch 1/20, step 591/829, loss: 468.2417297363281\n",
      "Epoch 1/20, step 601/829, loss: 421.2961120605469\n",
      "Epoch 1/20, step 611/829, loss: 418.3546447753906\n",
      "Epoch 1/20, step 621/829, loss: 329.3475036621094\n",
      "Epoch 1/20, step 631/829, loss: 291.13677978515625\n",
      "Epoch 1/20, step 641/829, loss: 252.85003662109375\n",
      "Epoch 1/20, step 651/829, loss: 250.40101623535156\n",
      "Epoch 1/20, step 661/829, loss: 284.65203857421875\n",
      "Epoch 1/20, step 671/829, loss: 234.09439086914062\n",
      "Epoch 1/20, step 681/829, loss: 222.08804321289062\n",
      "Epoch 1/20, step 691/829, loss: 177.88880920410156\n",
      "Epoch 1/20, step 701/829, loss: 245.58590698242188\n",
      "Epoch 1/20, step 711/829, loss: 170.16940307617188\n",
      "Epoch 1/20, step 721/829, loss: 104.35004425048828\n",
      "Epoch 1/20, step 731/829, loss: 203.03729248046875\n",
      "Epoch 1/20, step 741/829, loss: 109.68614196777344\n",
      "Epoch 1/20, step 751/829, loss: 131.75755310058594\n",
      "Epoch 1/20, step 761/829, loss: 137.5482940673828\n",
      "Epoch 1/20, step 771/829, loss: 169.3277130126953\n",
      "Epoch 1/20, step 781/829, loss: 184.81634521484375\n",
      "Epoch 1/20, step 791/829, loss: 79.61140441894531\n",
      "Epoch 1/20, step 801/829, loss: 136.52532958984375\n",
      "Epoch 1/20, step 811/829, loss: 99.7103500366211\n",
      "Epoch 1/20, step 821/829, loss: 80.46138000488281\n",
      "Epoch 2/20, step 1/829, loss: 130.48959350585938\n",
      "Epoch 2/20, step 11/829, loss: 110.01272583007812\n",
      "Epoch 2/20, step 21/829, loss: 71.30659484863281\n",
      "Epoch 2/20, step 31/829, loss: 58.61506652832031\n",
      "Epoch 2/20, step 41/829, loss: 92.89228820800781\n",
      "Epoch 2/20, step 51/829, loss: 81.90626525878906\n",
      "Epoch 2/20, step 61/829, loss: 72.33624267578125\n",
      "Epoch 2/20, step 71/829, loss: 57.70674514770508\n",
      "Epoch 2/20, step 81/829, loss: 108.63359069824219\n",
      "Epoch 2/20, step 91/829, loss: 69.56932067871094\n",
      "Epoch 2/20, step 101/829, loss: 64.50639343261719\n",
      "Epoch 2/20, step 111/829, loss: 80.78099060058594\n",
      "Epoch 2/20, step 121/829, loss: 522.5458984375\n",
      "Epoch 2/20, step 131/829, loss: 60.72875213623047\n",
      "Epoch 2/20, step 141/829, loss: 50.214454650878906\n",
      "Epoch 2/20, step 151/829, loss: 67.3558578491211\n",
      "Epoch 2/20, step 161/829, loss: 30.371379852294922\n",
      "Epoch 2/20, step 171/829, loss: 41.937599182128906\n",
      "Epoch 2/20, step 181/829, loss: 40.795162200927734\n",
      "Epoch 2/20, step 191/829, loss: 35.072296142578125\n",
      "Epoch 2/20, step 201/829, loss: 55.47357940673828\n",
      "Epoch 2/20, step 211/829, loss: 93.83138275146484\n",
      "Epoch 2/20, step 221/829, loss: 34.74300003051758\n",
      "Epoch 2/20, step 231/829, loss: 67.82491302490234\n",
      "Epoch 2/20, step 241/829, loss: 32.797637939453125\n",
      "Epoch 2/20, step 251/829, loss: 57.677215576171875\n",
      "Epoch 2/20, step 261/829, loss: 56.512847900390625\n",
      "Epoch 2/20, step 271/829, loss: 39.63187789916992\n",
      "Epoch 2/20, step 281/829, loss: 52.90080261230469\n",
      "Epoch 2/20, step 291/829, loss: 26.19184112548828\n",
      "Epoch 2/20, step 301/829, loss: 46.583763122558594\n",
      "Epoch 2/20, step 311/829, loss: 58.08788299560547\n",
      "Epoch 2/20, step 321/829, loss: 30.860233306884766\n",
      "Epoch 2/20, step 331/829, loss: 133.68194580078125\n",
      "Epoch 2/20, step 341/829, loss: 44.61772155761719\n",
      "Epoch 2/20, step 351/829, loss: 50.97578048706055\n",
      "Epoch 2/20, step 361/829, loss: 44.62444305419922\n",
      "Epoch 2/20, step 371/829, loss: 39.0360107421875\n",
      "Epoch 2/20, step 381/829, loss: 32.63185119628906\n",
      "Epoch 2/20, step 391/829, loss: 54.03327560424805\n",
      "Epoch 2/20, step 401/829, loss: 41.2893180847168\n",
      "Epoch 2/20, step 411/829, loss: 27.489046096801758\n",
      "Epoch 2/20, step 421/829, loss: 70.25767517089844\n",
      "Epoch 2/20, step 431/829, loss: 37.47276306152344\n",
      "Epoch 2/20, step 441/829, loss: 71.76207733154297\n",
      "Epoch 2/20, step 451/829, loss: 25.077848434448242\n",
      "Epoch 2/20, step 461/829, loss: 40.017513275146484\n",
      "Epoch 2/20, step 471/829, loss: 35.744720458984375\n",
      "Epoch 2/20, step 481/829, loss: 35.01433181762695\n",
      "Epoch 2/20, step 491/829, loss: 50.74626541137695\n",
      "Epoch 2/20, step 501/829, loss: 28.382862091064453\n",
      "Epoch 2/20, step 511/829, loss: 39.63671875\n",
      "Epoch 2/20, step 521/829, loss: 32.50592803955078\n",
      "Epoch 2/20, step 531/829, loss: 60.81938552856445\n",
      "Epoch 2/20, step 541/829, loss: 45.69029235839844\n",
      "Epoch 2/20, step 551/829, loss: 33.59076690673828\n",
      "Epoch 2/20, step 561/829, loss: 35.439083099365234\n",
      "Epoch 2/20, step 571/829, loss: 38.19523620605469\n",
      "Epoch 2/20, step 581/829, loss: 42.00645446777344\n",
      "Epoch 2/20, step 591/829, loss: 40.56975173950195\n",
      "Epoch 2/20, step 601/829, loss: 37.64653396606445\n",
      "Epoch 2/20, step 611/829, loss: 15.793485641479492\n",
      "Epoch 2/20, step 621/829, loss: 30.095067977905273\n",
      "Epoch 2/20, step 631/829, loss: 35.15203857421875\n",
      "Epoch 2/20, step 641/829, loss: 32.96299362182617\n",
      "Epoch 2/20, step 651/829, loss: 18.547340393066406\n",
      "Epoch 2/20, step 661/829, loss: 40.20574951171875\n",
      "Epoch 2/20, step 671/829, loss: 37.86941146850586\n",
      "Epoch 2/20, step 681/829, loss: 20.826505661010742\n",
      "Epoch 2/20, step 691/829, loss: 47.27602005004883\n",
      "Epoch 2/20, step 701/829, loss: 111.07904052734375\n",
      "Epoch 2/20, step 711/829, loss: 74.63616180419922\n",
      "Epoch 2/20, step 721/829, loss: 25.681461334228516\n",
      "Epoch 2/20, step 731/829, loss: 32.34030532836914\n",
      "Epoch 2/20, step 741/829, loss: 22.363630294799805\n",
      "Epoch 2/20, step 751/829, loss: 56.75096893310547\n",
      "Epoch 2/20, step 761/829, loss: 24.873008728027344\n",
      "Epoch 2/20, step 771/829, loss: 47.725467681884766\n",
      "Epoch 2/20, step 781/829, loss: 18.300626754760742\n",
      "Epoch 2/20, step 791/829, loss: 25.14802360534668\n",
      "Epoch 2/20, step 801/829, loss: 34.49546432495117\n",
      "Epoch 2/20, step 811/829, loss: 60.76413345336914\n",
      "Epoch 2/20, step 821/829, loss: 34.92152404785156\n",
      "Epoch 3/20, step 1/829, loss: 20.343976974487305\n",
      "Epoch 3/20, step 11/829, loss: 106.93319702148438\n",
      "Epoch 3/20, step 21/829, loss: 21.12531089782715\n",
      "Epoch 3/20, step 31/829, loss: 14.682342529296875\n",
      "Epoch 3/20, step 41/829, loss: 62.05976486206055\n",
      "Epoch 3/20, step 51/829, loss: 24.485536575317383\n",
      "Epoch 3/20, step 61/829, loss: 16.579782485961914\n",
      "Epoch 3/20, step 71/829, loss: 69.94025421142578\n",
      "Epoch 3/20, step 81/829, loss: 15.42332935333252\n",
      "Epoch 3/20, step 91/829, loss: 40.70841598510742\n",
      "Epoch 3/20, step 101/829, loss: 36.24336242675781\n",
      "Epoch 3/20, step 111/829, loss: 27.282360076904297\n",
      "Epoch 3/20, step 121/829, loss: 30.197280883789062\n",
      "Epoch 3/20, step 131/829, loss: 16.00714111328125\n",
      "Epoch 3/20, step 141/829, loss: 28.53304100036621\n",
      "Epoch 3/20, step 151/829, loss: 52.98788070678711\n",
      "Epoch 3/20, step 161/829, loss: 45.85714340209961\n",
      "Epoch 3/20, step 171/829, loss: 60.71800231933594\n",
      "Epoch 3/20, step 181/829, loss: 62.81221389770508\n",
      "Epoch 3/20, step 191/829, loss: 11.337383270263672\n",
      "Epoch 3/20, step 201/829, loss: 30.28615951538086\n",
      "Epoch 3/20, step 211/829, loss: 36.42255783081055\n",
      "Epoch 3/20, step 221/829, loss: 21.867162704467773\n",
      "Epoch 3/20, step 231/829, loss: 35.33250427246094\n",
      "Epoch 3/20, step 241/829, loss: 36.32094955444336\n",
      "Epoch 3/20, step 251/829, loss: 22.514732360839844\n",
      "Epoch 3/20, step 261/829, loss: 40.671043395996094\n",
      "Epoch 3/20, step 271/829, loss: 21.741111755371094\n",
      "Epoch 3/20, step 281/829, loss: 38.17811584472656\n",
      "Epoch 3/20, step 291/829, loss: 14.448931694030762\n",
      "Epoch 3/20, step 301/829, loss: 31.533672332763672\n",
      "Epoch 3/20, step 311/829, loss: 25.428274154663086\n",
      "Epoch 3/20, step 321/829, loss: 36.47541046142578\n",
      "Epoch 3/20, step 331/829, loss: 73.7280502319336\n",
      "Epoch 3/20, step 341/829, loss: 37.51618576049805\n",
      "Epoch 3/20, step 351/829, loss: 83.96951293945312\n",
      "Epoch 3/20, step 361/829, loss: 9.38501262664795\n",
      "Epoch 3/20, step 371/829, loss: 10.554754257202148\n",
      "Epoch 3/20, step 381/829, loss: 9.791821479797363\n",
      "Epoch 3/20, step 391/829, loss: 20.161115646362305\n",
      "Epoch 3/20, step 401/829, loss: 14.07936954498291\n",
      "Epoch 3/20, step 411/829, loss: 16.732006072998047\n",
      "Epoch 3/20, step 421/829, loss: 9.030906677246094\n",
      "Epoch 3/20, step 431/829, loss: 20.51519775390625\n",
      "Epoch 3/20, step 441/829, loss: 12.372305870056152\n",
      "Epoch 3/20, step 451/829, loss: 22.93372917175293\n",
      "Epoch 3/20, step 461/829, loss: 47.459144592285156\n",
      "Epoch 3/20, step 471/829, loss: 98.22602844238281\n",
      "Epoch 3/20, step 481/829, loss: 40.89075469970703\n",
      "Epoch 3/20, step 491/829, loss: 30.36431121826172\n",
      "Epoch 3/20, step 501/829, loss: 12.69856071472168\n",
      "Epoch 3/20, step 511/829, loss: 14.936030387878418\n",
      "Epoch 3/20, step 521/829, loss: 34.51282501220703\n",
      "Epoch 3/20, step 531/829, loss: 26.051021575927734\n",
      "Epoch 3/20, step 541/829, loss: 40.19655227661133\n",
      "Epoch 3/20, step 551/829, loss: 9.412982940673828\n",
      "Epoch 3/20, step 561/829, loss: 10.916964530944824\n",
      "Epoch 3/20, step 571/829, loss: 140.98194885253906\n",
      "Epoch 3/20, step 581/829, loss: 18.41354751586914\n",
      "Epoch 3/20, step 591/829, loss: 6.481999397277832\n",
      "Epoch 3/20, step 601/829, loss: 16.54180145263672\n",
      "Epoch 3/20, step 611/829, loss: 20.2210750579834\n",
      "Epoch 3/20, step 621/829, loss: 23.97005271911621\n",
      "Epoch 3/20, step 631/829, loss: 21.219770431518555\n",
      "Epoch 3/20, step 641/829, loss: 29.443300247192383\n",
      "Epoch 3/20, step 651/829, loss: 27.966812133789062\n",
      "Epoch 3/20, step 661/829, loss: 12.766996383666992\n",
      "Epoch 3/20, step 671/829, loss: 35.2829475402832\n",
      "Epoch 3/20, step 681/829, loss: 47.06828308105469\n",
      "Epoch 3/20, step 691/829, loss: 30.577180862426758\n",
      "Epoch 3/20, step 701/829, loss: 31.46205711364746\n",
      "Epoch 3/20, step 711/829, loss: 25.602657318115234\n",
      "Epoch 3/20, step 721/829, loss: 21.766986846923828\n",
      "Epoch 3/20, step 731/829, loss: 30.973085403442383\n",
      "Epoch 3/20, step 741/829, loss: 15.154072761535645\n",
      "Epoch 3/20, step 751/829, loss: 24.246822357177734\n",
      "Epoch 3/20, step 761/829, loss: 13.515583038330078\n",
      "Epoch 3/20, step 771/829, loss: 29.580795288085938\n",
      "Epoch 3/20, step 781/829, loss: 9.775642395019531\n",
      "Epoch 3/20, step 791/829, loss: 48.44639587402344\n",
      "Epoch 3/20, step 801/829, loss: 8.109708786010742\n",
      "Epoch 3/20, step 811/829, loss: 28.983156204223633\n",
      "Epoch 3/20, step 821/829, loss: 12.236339569091797\n",
      "Epoch 4/20, step 1/829, loss: 49.831119537353516\n",
      "Epoch 4/20, step 11/829, loss: 14.895252227783203\n",
      "Epoch 4/20, step 21/829, loss: 13.483333587646484\n",
      "Epoch 4/20, step 31/829, loss: 36.90776443481445\n",
      "Epoch 4/20, step 41/829, loss: 5.7001848220825195\n",
      "Epoch 4/20, step 51/829, loss: 10.309625625610352\n",
      "Epoch 4/20, step 61/829, loss: 14.03493881225586\n",
      "Epoch 4/20, step 71/829, loss: 12.463010787963867\n",
      "Epoch 4/20, step 81/829, loss: 22.173776626586914\n",
      "Epoch 4/20, step 91/829, loss: 6.341036319732666\n",
      "Epoch 4/20, step 101/829, loss: 42.16096115112305\n",
      "Epoch 4/20, step 111/829, loss: 27.276058197021484\n",
      "Epoch 4/20, step 121/829, loss: 31.50522232055664\n",
      "Epoch 4/20, step 131/829, loss: 29.498157501220703\n",
      "Epoch 4/20, step 141/829, loss: 29.048372268676758\n",
      "Epoch 4/20, step 151/829, loss: 11.478232383728027\n",
      "Epoch 4/20, step 161/829, loss: 10.697386741638184\n",
      "Epoch 4/20, step 171/829, loss: 9.562796592712402\n",
      "Epoch 4/20, step 181/829, loss: 8.41351318359375\n",
      "Epoch 4/20, step 191/829, loss: 11.498942375183105\n",
      "Epoch 4/20, step 201/829, loss: 132.65264892578125\n",
      "Epoch 4/20, step 211/829, loss: 30.326725006103516\n",
      "Epoch 4/20, step 221/829, loss: 16.242822647094727\n",
      "Epoch 4/20, step 231/829, loss: 14.542389869689941\n",
      "Epoch 4/20, step 241/829, loss: 9.799535751342773\n",
      "Epoch 4/20, step 251/829, loss: 17.357627868652344\n",
      "Epoch 4/20, step 261/829, loss: 11.102296829223633\n",
      "Epoch 4/20, step 271/829, loss: 18.023550033569336\n",
      "Epoch 4/20, step 281/829, loss: 17.18467903137207\n",
      "Epoch 4/20, step 291/829, loss: 6.983013153076172\n",
      "Epoch 4/20, step 301/829, loss: 20.94501495361328\n",
      "Epoch 4/20, step 311/829, loss: 9.255279541015625\n",
      "Epoch 4/20, step 321/829, loss: 15.871658325195312\n",
      "Epoch 4/20, step 331/829, loss: 30.034250259399414\n",
      "Epoch 4/20, step 341/829, loss: 17.220386505126953\n",
      "Epoch 4/20, step 351/829, loss: 8.368266105651855\n",
      "Epoch 4/20, step 361/829, loss: 5.390076160430908\n",
      "Epoch 4/20, step 371/829, loss: 22.769697189331055\n",
      "Epoch 4/20, step 381/829, loss: 10.733120918273926\n",
      "Epoch 4/20, step 391/829, loss: 13.069604873657227\n",
      "Epoch 4/20, step 401/829, loss: 19.683277130126953\n",
      "Epoch 4/20, step 411/829, loss: 10.3268461227417\n",
      "Epoch 4/20, step 421/829, loss: 6.249402046203613\n",
      "Epoch 4/20, step 431/829, loss: 7.675342559814453\n",
      "Epoch 4/20, step 441/829, loss: 11.994234085083008\n",
      "Epoch 4/20, step 451/829, loss: 13.604778289794922\n",
      "Epoch 4/20, step 461/829, loss: 10.416353225708008\n",
      "Epoch 4/20, step 471/829, loss: 9.061487197875977\n",
      "Epoch 4/20, step 481/829, loss: 17.271469116210938\n",
      "Epoch 4/20, step 491/829, loss: 9.417877197265625\n",
      "Epoch 4/20, step 501/829, loss: 37.93215560913086\n",
      "Epoch 4/20, step 511/829, loss: 9.500157356262207\n",
      "Epoch 4/20, step 521/829, loss: 5.5739264488220215\n",
      "Epoch 4/20, step 531/829, loss: 12.900415420532227\n",
      "Epoch 4/20, step 541/829, loss: 8.226764678955078\n",
      "Epoch 4/20, step 551/829, loss: 17.323476791381836\n",
      "Epoch 4/20, step 561/829, loss: 512.9216918945312\n",
      "Epoch 4/20, step 571/829, loss: 19.77267074584961\n",
      "Epoch 4/20, step 581/829, loss: 156.61167907714844\n",
      "Epoch 4/20, step 591/829, loss: 11.428799629211426\n",
      "Epoch 4/20, step 601/829, loss: 36.11772918701172\n",
      "Epoch 4/20, step 611/829, loss: 49.58666229248047\n",
      "Epoch 4/20, step 621/829, loss: 17.30597496032715\n",
      "Epoch 4/20, step 631/829, loss: 63.46217727661133\n",
      "Epoch 4/20, step 641/829, loss: 98.18363952636719\n",
      "Epoch 4/20, step 651/829, loss: 7.531682968139648\n",
      "Epoch 4/20, step 661/829, loss: 27.8790283203125\n",
      "Epoch 4/20, step 671/829, loss: 7.041801929473877\n",
      "Epoch 4/20, step 681/829, loss: 13.539281845092773\n",
      "Epoch 4/20, step 691/829, loss: 32.817481994628906\n",
      "Epoch 4/20, step 701/829, loss: 6.064998149871826\n",
      "Epoch 4/20, step 711/829, loss: 10.1553955078125\n",
      "Epoch 4/20, step 721/829, loss: 16.185544967651367\n",
      "Epoch 4/20, step 731/829, loss: 6.771493434906006\n",
      "Epoch 4/20, step 741/829, loss: 61.599857330322266\n",
      "Epoch 4/20, step 751/829, loss: 95.03107452392578\n",
      "Epoch 4/20, step 761/829, loss: 5.830417156219482\n",
      "Epoch 4/20, step 771/829, loss: 50.362979888916016\n",
      "Epoch 4/20, step 781/829, loss: 10.077312469482422\n",
      "Epoch 4/20, step 791/829, loss: 7.030594348907471\n",
      "Epoch 4/20, step 801/829, loss: 17.389724731445312\n",
      "Epoch 4/20, step 811/829, loss: 5.200061321258545\n",
      "Epoch 4/20, step 821/829, loss: 9.655210494995117\n",
      "Epoch 5/20, step 1/829, loss: 10.799559593200684\n",
      "Epoch 5/20, step 11/829, loss: 9.444732666015625\n",
      "Epoch 5/20, step 21/829, loss: 5.884776592254639\n",
      "Epoch 5/20, step 31/829, loss: 7.207369327545166\n",
      "Epoch 5/20, step 41/829, loss: 2.912372350692749\n",
      "Epoch 5/20, step 51/829, loss: 26.466548919677734\n",
      "Epoch 5/20, step 61/829, loss: 4.953496932983398\n",
      "Epoch 5/20, step 71/829, loss: 28.711116790771484\n",
      "Epoch 5/20, step 81/829, loss: 14.696317672729492\n",
      "Epoch 5/20, step 91/829, loss: 15.675037384033203\n",
      "Epoch 5/20, step 101/829, loss: 25.207365036010742\n",
      "Epoch 5/20, step 111/829, loss: 5.384923934936523\n",
      "Epoch 5/20, step 121/829, loss: 12.274161338806152\n",
      "Epoch 5/20, step 131/829, loss: 9.292403221130371\n",
      "Epoch 5/20, step 141/829, loss: 8.965373039245605\n",
      "Epoch 5/20, step 151/829, loss: 4.0378241539001465\n",
      "Epoch 5/20, step 161/829, loss: 10.677201271057129\n",
      "Epoch 5/20, step 171/829, loss: 12.194106101989746\n",
      "Epoch 5/20, step 181/829, loss: 10.846338272094727\n",
      "Epoch 5/20, step 191/829, loss: 12.937114715576172\n",
      "Epoch 5/20, step 201/829, loss: 13.02486801147461\n",
      "Epoch 5/20, step 211/829, loss: 24.22057342529297\n",
      "Epoch 5/20, step 221/829, loss: 16.315580368041992\n",
      "Epoch 5/20, step 231/829, loss: 109.8822021484375\n",
      "Epoch 5/20, step 241/829, loss: 5.718659400939941\n",
      "Epoch 5/20, step 251/829, loss: 18.00951385498047\n",
      "Epoch 5/20, step 261/829, loss: 8.739524841308594\n",
      "Epoch 5/20, step 271/829, loss: 13.661783218383789\n",
      "Epoch 5/20, step 281/829, loss: 5.444945335388184\n",
      "Epoch 5/20, step 291/829, loss: 7.447307586669922\n",
      "Epoch 5/20, step 301/829, loss: 22.52815055847168\n",
      "Epoch 5/20, step 311/829, loss: 12.066549301147461\n",
      "Epoch 5/20, step 321/829, loss: 23.210315704345703\n",
      "Epoch 5/20, step 331/829, loss: 4.889926910400391\n",
      "Epoch 5/20, step 341/829, loss: 27.51137924194336\n",
      "Epoch 5/20, step 351/829, loss: 14.27267074584961\n",
      "Epoch 5/20, step 361/829, loss: 20.33574867248535\n",
      "Epoch 5/20, step 371/829, loss: 12.17705249786377\n",
      "Epoch 5/20, step 381/829, loss: 12.487430572509766\n",
      "Epoch 5/20, step 391/829, loss: 17.924774169921875\n",
      "Epoch 5/20, step 401/829, loss: 12.974125862121582\n",
      "Epoch 5/20, step 411/829, loss: 11.969884872436523\n",
      "Epoch 5/20, step 421/829, loss: 30.925979614257812\n",
      "Epoch 5/20, step 431/829, loss: 9.290048599243164\n",
      "Epoch 5/20, step 441/829, loss: 5.988007545471191\n",
      "Epoch 5/20, step 451/829, loss: 8.067839622497559\n",
      "Epoch 5/20, step 461/829, loss: 11.14269733428955\n",
      "Epoch 5/20, step 471/829, loss: 7.793304920196533\n",
      "Epoch 5/20, step 481/829, loss: 84.46028900146484\n",
      "Epoch 5/20, step 491/829, loss: 24.175922393798828\n",
      "Epoch 5/20, step 501/829, loss: 8.835436820983887\n",
      "Epoch 5/20, step 511/829, loss: 11.149686813354492\n",
      "Epoch 5/20, step 521/829, loss: 24.66219139099121\n",
      "Epoch 5/20, step 531/829, loss: 16.239356994628906\n",
      "Epoch 5/20, step 541/829, loss: 6.386935710906982\n",
      "Epoch 5/20, step 551/829, loss: 5.400871753692627\n",
      "Epoch 5/20, step 561/829, loss: 4.9213385581970215\n",
      "Epoch 5/20, step 571/829, loss: 9.193706512451172\n",
      "Epoch 5/20, step 581/829, loss: 9.482065200805664\n",
      "Epoch 5/20, step 591/829, loss: 5.883028507232666\n",
      "Epoch 5/20, step 601/829, loss: 16.00050926208496\n",
      "Epoch 5/20, step 611/829, loss: 16.748546600341797\n",
      "Epoch 5/20, step 621/829, loss: 6.700566291809082\n",
      "Epoch 5/20, step 631/829, loss: 6.757814407348633\n",
      "Epoch 5/20, step 641/829, loss: 7.472509384155273\n",
      "Epoch 5/20, step 651/829, loss: 9.679789543151855\n",
      "Epoch 5/20, step 661/829, loss: 19.09994125366211\n",
      "Epoch 5/20, step 671/829, loss: 5.229647159576416\n",
      "Epoch 5/20, step 681/829, loss: 2.302978992462158\n",
      "Epoch 5/20, step 691/829, loss: 5.3795881271362305\n",
      "Epoch 5/20, step 701/829, loss: 18.222450256347656\n",
      "Epoch 5/20, step 711/829, loss: 4.749912261962891\n",
      "Epoch 5/20, step 721/829, loss: 5.842679023742676\n",
      "Epoch 5/20, step 731/829, loss: 29.221240997314453\n",
      "Epoch 5/20, step 741/829, loss: 16.996984481811523\n",
      "Epoch 5/20, step 751/829, loss: 18.937782287597656\n",
      "Epoch 5/20, step 761/829, loss: 8.979127883911133\n",
      "Epoch 5/20, step 771/829, loss: 9.652116775512695\n",
      "Epoch 5/20, step 781/829, loss: 4.471384525299072\n",
      "Epoch 5/20, step 791/829, loss: 12.283780097961426\n",
      "Epoch 5/20, step 801/829, loss: 14.676248550415039\n",
      "Epoch 5/20, step 811/829, loss: 30.489097595214844\n",
      "Epoch 5/20, step 821/829, loss: 5.403874397277832\n",
      "Epoch 6/20, step 1/829, loss: 4.4603657722473145\n",
      "Epoch 6/20, step 11/829, loss: 109.45704650878906\n",
      "Epoch 6/20, step 21/829, loss: 4.033540725708008\n",
      "Epoch 6/20, step 31/829, loss: 8.26452922821045\n",
      "Epoch 6/20, step 41/829, loss: 6.592848777770996\n",
      "Epoch 6/20, step 51/829, loss: 14.979866981506348\n",
      "Epoch 6/20, step 61/829, loss: 5.095854759216309\n",
      "Epoch 6/20, step 71/829, loss: 7.877862453460693\n",
      "Epoch 6/20, step 81/829, loss: 160.0955047607422\n",
      "Epoch 6/20, step 91/829, loss: 4.268496036529541\n",
      "Epoch 6/20, step 101/829, loss: 4.446744441986084\n",
      "Epoch 6/20, step 111/829, loss: 6.638636112213135\n",
      "Epoch 6/20, step 121/829, loss: 5.146174430847168\n",
      "Epoch 6/20, step 131/829, loss: 9.703474044799805\n",
      "Epoch 6/20, step 141/829, loss: 3.8530282974243164\n",
      "Epoch 6/20, step 151/829, loss: 4.024185657501221\n",
      "Epoch 6/20, step 161/829, loss: 4.077859401702881\n",
      "Epoch 6/20, step 171/829, loss: 3.040257692337036\n",
      "Epoch 6/20, step 181/829, loss: 1.9766838550567627\n",
      "Epoch 6/20, step 191/829, loss: 5.810834884643555\n",
      "Epoch 6/20, step 201/829, loss: 3.2460851669311523\n",
      "Epoch 6/20, step 211/829, loss: 4.0367021560668945\n",
      "Epoch 6/20, step 221/829, loss: 15.510011672973633\n",
      "Epoch 6/20, step 231/829, loss: 35.761898040771484\n",
      "Epoch 6/20, step 241/829, loss: 3.5376017093658447\n",
      "Epoch 6/20, step 251/829, loss: 15.863533020019531\n",
      "Epoch 6/20, step 261/829, loss: 15.3570556640625\n",
      "Epoch 6/20, step 271/829, loss: 8.171747207641602\n",
      "Epoch 6/20, step 281/829, loss: 15.995378494262695\n",
      "Epoch 6/20, step 291/829, loss: 18.647430419921875\n",
      "Epoch 6/20, step 301/829, loss: 14.975902557373047\n",
      "Epoch 6/20, step 311/829, loss: 5.969159126281738\n",
      "Epoch 6/20, step 321/829, loss: 15.724010467529297\n",
      "Epoch 6/20, step 331/829, loss: 10.50229263305664\n",
      "Epoch 6/20, step 341/829, loss: 2.7342607975006104\n",
      "Epoch 6/20, step 351/829, loss: 22.284116744995117\n",
      "Epoch 6/20, step 361/829, loss: 4.065154552459717\n",
      "Epoch 6/20, step 371/829, loss: 3.9353153705596924\n",
      "Epoch 6/20, step 381/829, loss: 6.989076614379883\n",
      "Epoch 6/20, step 391/829, loss: 2.253801107406616\n",
      "Epoch 6/20, step 401/829, loss: 11.229602813720703\n",
      "Epoch 6/20, step 411/829, loss: 10.747770309448242\n",
      "Epoch 6/20, step 421/829, loss: 6.429138660430908\n",
      "Epoch 6/20, step 431/829, loss: 4.574625492095947\n",
      "Epoch 6/20, step 441/829, loss: 6.401680946350098\n",
      "Epoch 6/20, step 451/829, loss: 7.081079959869385\n",
      "Epoch 6/20, step 461/829, loss: 2.8956005573272705\n",
      "Epoch 6/20, step 471/829, loss: 2.309535264968872\n",
      "Epoch 6/20, step 481/829, loss: 8.545857429504395\n",
      "Epoch 6/20, step 491/829, loss: 2.266942262649536\n",
      "Epoch 6/20, step 501/829, loss: 7.7976765632629395\n",
      "Epoch 6/20, step 511/829, loss: 10.093521118164062\n",
      "Epoch 6/20, step 521/829, loss: 4.544651031494141\n",
      "Epoch 6/20, step 531/829, loss: 2.2455708980560303\n",
      "Epoch 6/20, step 541/829, loss: 8.538917541503906\n",
      "Epoch 6/20, step 551/829, loss: 15.827644348144531\n",
      "Epoch 6/20, step 561/829, loss: 5.175307273864746\n",
      "Epoch 6/20, step 571/829, loss: 4.364173412322998\n",
      "Epoch 6/20, step 581/829, loss: 10.06823444366455\n",
      "Epoch 6/20, step 591/829, loss: 3.686727523803711\n",
      "Epoch 6/20, step 601/829, loss: 3.8329660892486572\n",
      "Epoch 6/20, step 611/829, loss: 3.808037042617798\n",
      "Epoch 6/20, step 621/829, loss: 11.20862102508545\n",
      "Epoch 6/20, step 631/829, loss: 2.96506667137146\n",
      "Epoch 6/20, step 641/829, loss: 23.803834915161133\n",
      "Epoch 6/20, step 651/829, loss: 6.666372299194336\n",
      "Epoch 6/20, step 661/829, loss: 5.787658214569092\n",
      "Epoch 6/20, step 671/829, loss: 6.467127323150635\n",
      "Epoch 6/20, step 681/829, loss: 2.63356876373291\n",
      "Epoch 6/20, step 691/829, loss: 7.4556474685668945\n",
      "Epoch 6/20, step 701/829, loss: 3.4625468254089355\n",
      "Epoch 6/20, step 711/829, loss: 5.731360912322998\n",
      "Epoch 6/20, step 721/829, loss: 4.889700889587402\n",
      "Epoch 6/20, step 731/829, loss: 3.9883947372436523\n",
      "Epoch 6/20, step 741/829, loss: 6.099573612213135\n",
      "Epoch 6/20, step 751/829, loss: 5.387162685394287\n",
      "Epoch 6/20, step 761/829, loss: 5.845827579498291\n",
      "Epoch 6/20, step 771/829, loss: 4.122323513031006\n",
      "Epoch 6/20, step 781/829, loss: 7.670345783233643\n",
      "Epoch 6/20, step 791/829, loss: 78.07328796386719\n",
      "Epoch 6/20, step 801/829, loss: 7.077777862548828\n",
      "Epoch 6/20, step 811/829, loss: 11.916277885437012\n",
      "Epoch 6/20, step 821/829, loss: 2.840486764907837\n",
      "Epoch 7/20, step 1/829, loss: 2.958493947982788\n",
      "Epoch 7/20, step 11/829, loss: 2.925959587097168\n",
      "Epoch 7/20, step 21/829, loss: 15.724625587463379\n",
      "Epoch 7/20, step 31/829, loss: 7.348608493804932\n",
      "Epoch 7/20, step 41/829, loss: 6.740935325622559\n",
      "Epoch 7/20, step 51/829, loss: 4.09177827835083\n",
      "Epoch 7/20, step 61/829, loss: 86.5171890258789\n",
      "Epoch 7/20, step 71/829, loss: 56.37504577636719\n",
      "Epoch 7/20, step 81/829, loss: 11.413476943969727\n",
      "Epoch 7/20, step 91/829, loss: 6.947300910949707\n",
      "Epoch 7/20, step 101/829, loss: 12.304627418518066\n",
      "Epoch 7/20, step 111/829, loss: 12.699555397033691\n",
      "Epoch 7/20, step 121/829, loss: 14.32518196105957\n",
      "Epoch 7/20, step 131/829, loss: 2.84086537361145\n",
      "Epoch 7/20, step 141/829, loss: 7.356642723083496\n",
      "Epoch 7/20, step 151/829, loss: 3.508850574493408\n",
      "Epoch 7/20, step 161/829, loss: 7.233231544494629\n",
      "Epoch 7/20, step 171/829, loss: 4.688620567321777\n",
      "Epoch 7/20, step 181/829, loss: 8.136106491088867\n",
      "Epoch 7/20, step 191/829, loss: 5.34512996673584\n",
      "Epoch 7/20, step 201/829, loss: 4.13961124420166\n",
      "Epoch 7/20, step 211/829, loss: 9.87669849395752\n",
      "Epoch 7/20, step 221/829, loss: 65.2112045288086\n",
      "Epoch 7/20, step 231/829, loss: 7.857560157775879\n",
      "Epoch 7/20, step 241/829, loss: 10.347136497497559\n",
      "Epoch 7/20, step 251/829, loss: 11.452162742614746\n",
      "Epoch 7/20, step 261/829, loss: 14.2528715133667\n",
      "Epoch 7/20, step 271/829, loss: 14.93709659576416\n",
      "Epoch 7/20, step 281/829, loss: 34.19181823730469\n",
      "Epoch 7/20, step 291/829, loss: 7.036954879760742\n",
      "Epoch 7/20, step 301/829, loss: 1.484332799911499\n",
      "Epoch 7/20, step 311/829, loss: 36.85653305053711\n",
      "Epoch 7/20, step 321/829, loss: 5.4384026527404785\n",
      "Epoch 7/20, step 331/829, loss: 18.34346580505371\n",
      "Epoch 7/20, step 341/829, loss: 15.120518684387207\n",
      "Epoch 7/20, step 351/829, loss: 5.562806606292725\n",
      "Epoch 7/20, step 361/829, loss: 17.12145233154297\n",
      "Epoch 7/20, step 371/829, loss: 3.9664275646209717\n",
      "Epoch 7/20, step 381/829, loss: 2.5042340755462646\n",
      "Epoch 7/20, step 391/829, loss: 1.922855019569397\n",
      "Epoch 7/20, step 401/829, loss: 4.883483409881592\n",
      "Epoch 7/20, step 411/829, loss: 6.651867389678955\n",
      "Epoch 7/20, step 421/829, loss: 9.098186492919922\n",
      "Epoch 7/20, step 431/829, loss: 3.7667155265808105\n",
      "Epoch 7/20, step 441/829, loss: 13.934161186218262\n",
      "Epoch 7/20, step 451/829, loss: 6.463071346282959\n",
      "Epoch 7/20, step 461/829, loss: 3.2258362770080566\n",
      "Epoch 7/20, step 471/829, loss: 3.5462570190429688\n",
      "Epoch 7/20, step 481/829, loss: 2.5477006435394287\n",
      "Epoch 7/20, step 491/829, loss: 4.72167444229126\n",
      "Epoch 7/20, step 501/829, loss: 10.064475059509277\n",
      "Epoch 7/20, step 511/829, loss: 1.3932641744613647\n",
      "Epoch 7/20, step 521/829, loss: 24.66716194152832\n",
      "Epoch 7/20, step 531/829, loss: 6.642760753631592\n",
      "Epoch 7/20, step 541/829, loss: 2.408313035964966\n",
      "Epoch 7/20, step 551/829, loss: 6.648240566253662\n",
      "Epoch 7/20, step 561/829, loss: 7.789938926696777\n",
      "Epoch 7/20, step 571/829, loss: 5.667953968048096\n",
      "Epoch 7/20, step 581/829, loss: 1.304736852645874\n",
      "Epoch 7/20, step 591/829, loss: 4.385324954986572\n",
      "Epoch 7/20, step 601/829, loss: 3.2191154956817627\n",
      "Epoch 7/20, step 611/829, loss: 1.2579188346862793\n",
      "Epoch 7/20, step 621/829, loss: 14.228791236877441\n",
      "Epoch 7/20, step 631/829, loss: 6.259780406951904\n",
      "Epoch 7/20, step 641/829, loss: 4.763230800628662\n",
      "Epoch 7/20, step 651/829, loss: 12.345314979553223\n",
      "Epoch 7/20, step 661/829, loss: 1.300254225730896\n",
      "Epoch 7/20, step 671/829, loss: 5.026399612426758\n",
      "Epoch 7/20, step 681/829, loss: 1.881710410118103\n",
      "Epoch 7/20, step 691/829, loss: 9.482878684997559\n",
      "Epoch 7/20, step 701/829, loss: 4.344427585601807\n",
      "Epoch 7/20, step 711/829, loss: 3.046823263168335\n",
      "Epoch 7/20, step 721/829, loss: 6.80855131149292\n",
      "Epoch 7/20, step 731/829, loss: 2.5211613178253174\n",
      "Epoch 7/20, step 741/829, loss: 91.80754852294922\n",
      "Epoch 7/20, step 751/829, loss: 2.14833402633667\n",
      "Epoch 7/20, step 761/829, loss: 5.386684894561768\n",
      "Epoch 7/20, step 771/829, loss: 2.9827301502227783\n",
      "Epoch 7/20, step 781/829, loss: 2.040644407272339\n",
      "Epoch 7/20, step 791/829, loss: 4.522070407867432\n",
      "Epoch 7/20, step 801/829, loss: 3.4948604106903076\n",
      "Epoch 7/20, step 811/829, loss: 3.38144850730896\n",
      "Epoch 7/20, step 821/829, loss: 6.379229545593262\n",
      "Epoch 8/20, step 1/829, loss: 6.060427188873291\n",
      "Epoch 8/20, step 11/829, loss: 7.7363481521606445\n",
      "Epoch 8/20, step 21/829, loss: 5.028500556945801\n",
      "Epoch 8/20, step 31/829, loss: 2.4259190559387207\n",
      "Epoch 8/20, step 41/829, loss: 4.88239860534668\n",
      "Epoch 8/20, step 51/829, loss: 26.5008602142334\n",
      "Epoch 8/20, step 61/829, loss: 4.805203914642334\n",
      "Epoch 8/20, step 71/829, loss: 7.849573612213135\n",
      "Epoch 8/20, step 81/829, loss: 2.7510504722595215\n",
      "Epoch 8/20, step 91/829, loss: 16.464773178100586\n",
      "Epoch 8/20, step 101/829, loss: 3.5190017223358154\n",
      "Epoch 8/20, step 111/829, loss: 10.87807846069336\n",
      "Epoch 8/20, step 121/829, loss: 2.553403377532959\n",
      "Epoch 8/20, step 131/829, loss: 9.540461540222168\n",
      "Epoch 8/20, step 141/829, loss: 4.352090358734131\n",
      "Epoch 8/20, step 151/829, loss: 15.168375968933105\n",
      "Epoch 8/20, step 161/829, loss: 4.704745292663574\n",
      "Epoch 8/20, step 171/829, loss: 50.413490295410156\n",
      "Epoch 8/20, step 181/829, loss: 4.567061424255371\n",
      "Epoch 8/20, step 191/829, loss: 6.2378621101379395\n",
      "Epoch 8/20, step 201/829, loss: 75.3770980834961\n",
      "Epoch 8/20, step 211/829, loss: 3.8721108436584473\n",
      "Epoch 8/20, step 221/829, loss: 43.057945251464844\n",
      "Epoch 8/20, step 231/829, loss: 4.451866149902344\n",
      "Epoch 8/20, step 241/829, loss: 4.306426048278809\n",
      "Epoch 8/20, step 251/829, loss: 4.193578720092773\n",
      "Epoch 8/20, step 261/829, loss: 3.767002820968628\n",
      "Epoch 8/20, step 271/829, loss: 27.66101837158203\n",
      "Epoch 8/20, step 281/829, loss: 2.735863447189331\n",
      "Epoch 8/20, step 291/829, loss: 5.029595375061035\n",
      "Epoch 8/20, step 301/829, loss: 5.491733074188232\n",
      "Epoch 8/20, step 311/829, loss: 3.809518814086914\n",
      "Epoch 8/20, step 321/829, loss: 5.775712013244629\n",
      "Epoch 8/20, step 331/829, loss: 15.276327133178711\n",
      "Epoch 8/20, step 341/829, loss: 1.8396943807601929\n",
      "Epoch 8/20, step 351/829, loss: 2.661987781524658\n",
      "Epoch 8/20, step 361/829, loss: 27.019445419311523\n",
      "Epoch 8/20, step 371/829, loss: 4.193568706512451\n",
      "Epoch 8/20, step 381/829, loss: 12.768190383911133\n",
      "Epoch 8/20, step 391/829, loss: 3.069441318511963\n",
      "Epoch 8/20, step 401/829, loss: 5.986508846282959\n",
      "Epoch 8/20, step 411/829, loss: 2.922466993331909\n",
      "Epoch 8/20, step 421/829, loss: 5.748836994171143\n",
      "Epoch 8/20, step 431/829, loss: 2.747460126876831\n",
      "Epoch 8/20, step 441/829, loss: 9.605314254760742\n",
      "Epoch 8/20, step 451/829, loss: 2.9995150566101074\n",
      "Epoch 8/20, step 461/829, loss: 5.337337017059326\n",
      "Epoch 8/20, step 471/829, loss: 3.995107650756836\n",
      "Epoch 8/20, step 481/829, loss: 1.579810619354248\n",
      "Epoch 8/20, step 491/829, loss: 2.137326955795288\n",
      "Epoch 8/20, step 501/829, loss: 3.371220350265503\n",
      "Epoch 8/20, step 511/829, loss: 14.918496131896973\n",
      "Epoch 8/20, step 521/829, loss: 6.717496871948242\n",
      "Epoch 8/20, step 531/829, loss: 7.355473041534424\n",
      "Epoch 8/20, step 541/829, loss: 20.054649353027344\n",
      "Epoch 8/20, step 551/829, loss: 25.03390121459961\n",
      "Epoch 8/20, step 561/829, loss: 5.1483473777771\n",
      "Epoch 8/20, step 571/829, loss: 2.706408739089966\n",
      "Epoch 8/20, step 581/829, loss: 8.058000564575195\n",
      "Epoch 8/20, step 591/829, loss: 3.459484577178955\n",
      "Epoch 8/20, step 601/829, loss: 320.4255065917969\n",
      "Epoch 8/20, step 611/829, loss: 9.413411140441895\n",
      "Epoch 8/20, step 621/829, loss: 6.998874664306641\n",
      "Epoch 8/20, step 631/829, loss: 3.954218864440918\n",
      "Epoch 8/20, step 641/829, loss: 2.505618095397949\n",
      "Epoch 8/20, step 651/829, loss: 4.149362564086914\n",
      "Epoch 8/20, step 661/829, loss: 1.7672170400619507\n",
      "Epoch 8/20, step 671/829, loss: 1.1412521600723267\n",
      "Epoch 8/20, step 681/829, loss: 16.40667724609375\n",
      "Epoch 8/20, step 691/829, loss: 15.835491180419922\n",
      "Epoch 8/20, step 701/829, loss: 13.794185638427734\n",
      "Epoch 8/20, step 711/829, loss: 3.020202398300171\n",
      "Epoch 8/20, step 721/829, loss: 3.2350289821624756\n",
      "Epoch 8/20, step 731/829, loss: 5.1866326332092285\n",
      "Epoch 8/20, step 741/829, loss: 3.5493853092193604\n",
      "Epoch 8/20, step 751/829, loss: 5.221404075622559\n",
      "Epoch 8/20, step 761/829, loss: 2.2179951667785645\n",
      "Epoch 8/20, step 771/829, loss: 3.464571952819824\n",
      "Epoch 8/20, step 781/829, loss: 16.864944458007812\n",
      "Epoch 8/20, step 791/829, loss: 9.957719802856445\n",
      "Epoch 8/20, step 801/829, loss: 1.0460286140441895\n",
      "Epoch 8/20, step 811/829, loss: 5.794802665710449\n",
      "Epoch 8/20, step 821/829, loss: 3.16337513923645\n",
      "Epoch 9/20, step 1/829, loss: 2.4902687072753906\n",
      "Epoch 9/20, step 11/829, loss: 1.4492764472961426\n",
      "Epoch 9/20, step 21/829, loss: 3.214919328689575\n",
      "Epoch 9/20, step 31/829, loss: 4.969409942626953\n",
      "Epoch 9/20, step 41/829, loss: 3.88505482673645\n",
      "Epoch 9/20, step 51/829, loss: 4.1019721031188965\n",
      "Epoch 9/20, step 61/829, loss: 6.99304723739624\n",
      "Epoch 9/20, step 71/829, loss: 3.7794108390808105\n",
      "Epoch 9/20, step 81/829, loss: 101.3364486694336\n",
      "Epoch 9/20, step 91/829, loss: 4.483631134033203\n",
      "Epoch 9/20, step 101/829, loss: 1.6533740758895874\n",
      "Epoch 9/20, step 111/829, loss: 7.413094520568848\n",
      "Epoch 9/20, step 121/829, loss: 10.865771293640137\n",
      "Epoch 9/20, step 131/829, loss: 7.129950523376465\n",
      "Epoch 9/20, step 141/829, loss: 3.591874361038208\n",
      "Epoch 9/20, step 151/829, loss: 4.181643009185791\n",
      "Epoch 9/20, step 161/829, loss: 4.862692832946777\n",
      "Epoch 9/20, step 171/829, loss: 11.160164833068848\n",
      "Epoch 9/20, step 181/829, loss: 11.219586372375488\n",
      "Epoch 9/20, step 191/829, loss: 7.914571762084961\n",
      "Epoch 9/20, step 201/829, loss: 2.001208782196045\n",
      "Epoch 9/20, step 211/829, loss: 10.39088249206543\n",
      "Epoch 9/20, step 221/829, loss: 1.2875967025756836\n",
      "Epoch 9/20, step 231/829, loss: 9.787130355834961\n",
      "Epoch 9/20, step 241/829, loss: 2.2081031799316406\n",
      "Epoch 9/20, step 251/829, loss: 2.2121920585632324\n",
      "Epoch 9/20, step 261/829, loss: 6.463250160217285\n",
      "Epoch 9/20, step 271/829, loss: 2.1585943698883057\n",
      "Epoch 9/20, step 281/829, loss: 3.466460704803467\n",
      "Epoch 9/20, step 291/829, loss: 1.3112283945083618\n",
      "Epoch 9/20, step 301/829, loss: 4.116734981536865\n",
      "Epoch 9/20, step 311/829, loss: 8.762264251708984\n",
      "Epoch 9/20, step 321/829, loss: 4.843196392059326\n",
      "Epoch 9/20, step 331/829, loss: 10.353553771972656\n",
      "Epoch 9/20, step 341/829, loss: 6.413327693939209\n",
      "Epoch 9/20, step 351/829, loss: 1.5730730295181274\n",
      "Epoch 9/20, step 361/829, loss: 11.93165111541748\n",
      "Epoch 9/20, step 371/829, loss: 21.63295555114746\n",
      "Epoch 9/20, step 381/829, loss: 5.156950950622559\n",
      "Epoch 9/20, step 391/829, loss: 20.531185150146484\n",
      "Epoch 9/20, step 401/829, loss: 1.854629635810852\n",
      "Epoch 9/20, step 411/829, loss: 2.888432502746582\n",
      "Epoch 9/20, step 421/829, loss: 1.366676688194275\n",
      "Epoch 9/20, step 431/829, loss: 7.27544641494751\n",
      "Epoch 9/20, step 441/829, loss: 0.7941961884498596\n",
      "Epoch 9/20, step 451/829, loss: 2.517421007156372\n",
      "Epoch 9/20, step 461/829, loss: 4.457483768463135\n",
      "Epoch 9/20, step 471/829, loss: 2.2066810131073\n",
      "Epoch 9/20, step 481/829, loss: 2.7307310104370117\n",
      "Epoch 9/20, step 491/829, loss: 3.9270272254943848\n",
      "Epoch 9/20, step 501/829, loss: 1.258497714996338\n",
      "Epoch 9/20, step 511/829, loss: 13.665752410888672\n",
      "Epoch 9/20, step 521/829, loss: 5.709826946258545\n",
      "Epoch 9/20, step 531/829, loss: 83.629150390625\n",
      "Epoch 9/20, step 541/829, loss: 1.7462358474731445\n",
      "Epoch 9/20, step 551/829, loss: 5.7853288650512695\n",
      "Epoch 9/20, step 561/829, loss: 2.2306153774261475\n",
      "Epoch 9/20, step 571/829, loss: 33.255943298339844\n",
      "Epoch 9/20, step 581/829, loss: 1.1964161396026611\n",
      "Epoch 9/20, step 591/829, loss: 11.250716209411621\n",
      "Epoch 9/20, step 601/829, loss: 5.026113510131836\n",
      "Epoch 9/20, step 611/829, loss: 2.603886604309082\n",
      "Epoch 9/20, step 621/829, loss: 5.910905361175537\n",
      "Epoch 9/20, step 631/829, loss: 10.396407127380371\n",
      "Epoch 9/20, step 641/829, loss: 2.2158119678497314\n",
      "Epoch 9/20, step 651/829, loss: 3.410609245300293\n",
      "Epoch 9/20, step 661/829, loss: 3.606062650680542\n",
      "Epoch 9/20, step 671/829, loss: 1.8826196193695068\n",
      "Epoch 9/20, step 681/829, loss: 2.309095859527588\n",
      "Epoch 9/20, step 691/829, loss: 4.163069248199463\n",
      "Epoch 9/20, step 701/829, loss: 1.860097885131836\n",
      "Epoch 9/20, step 711/829, loss: 3.8532989025115967\n",
      "Epoch 9/20, step 721/829, loss: 0.9656675457954407\n",
      "Epoch 9/20, step 731/829, loss: 3.268911838531494\n",
      "Epoch 9/20, step 741/829, loss: 11.758042335510254\n",
      "Epoch 9/20, step 751/829, loss: 1.0649535655975342\n",
      "Epoch 9/20, step 761/829, loss: 5.6628642082214355\n",
      "Epoch 9/20, step 771/829, loss: 13.623202323913574\n",
      "Epoch 9/20, step 781/829, loss: 3.927748203277588\n",
      "Epoch 9/20, step 791/829, loss: 7.6115217208862305\n",
      "Epoch 9/20, step 801/829, loss: 2.3157856464385986\n",
      "Epoch 9/20, step 811/829, loss: 2.1326451301574707\n",
      "Epoch 9/20, step 821/829, loss: 2.7022602558135986\n",
      "Epoch 10/20, step 1/829, loss: 2.589071273803711\n",
      "Epoch 10/20, step 11/829, loss: 5.299067497253418\n",
      "Epoch 10/20, step 21/829, loss: 74.67729949951172\n",
      "Epoch 10/20, step 31/829, loss: 7.13814640045166\n",
      "Epoch 10/20, step 41/829, loss: 3.595897912979126\n",
      "Epoch 10/20, step 51/829, loss: 1.3297985792160034\n",
      "Epoch 10/20, step 61/829, loss: 3.461638927459717\n",
      "Epoch 10/20, step 71/829, loss: 3.438854455947876\n",
      "Epoch 10/20, step 81/829, loss: 2.2788548469543457\n",
      "Epoch 10/20, step 91/829, loss: 1.9592310190200806\n",
      "Epoch 10/20, step 101/829, loss: 2.165329694747925\n",
      "Epoch 10/20, step 111/829, loss: 1.7547913789749146\n",
      "Epoch 10/20, step 121/829, loss: 3.3958940505981445\n",
      "Epoch 10/20, step 131/829, loss: 3.642402172088623\n",
      "Epoch 10/20, step 141/829, loss: 2.9836225509643555\n",
      "Epoch 10/20, step 151/829, loss: 2.0547304153442383\n",
      "Epoch 10/20, step 161/829, loss: 3.6569392681121826\n",
      "Epoch 10/20, step 171/829, loss: 19.71355438232422\n",
      "Epoch 10/20, step 181/829, loss: 1.6425687074661255\n",
      "Epoch 10/20, step 191/829, loss: 3.1541829109191895\n",
      "Epoch 10/20, step 201/829, loss: 2.3686065673828125\n",
      "Epoch 10/20, step 211/829, loss: 0.5731867551803589\n",
      "Epoch 10/20, step 221/829, loss: 1.4363328218460083\n",
      "Epoch 10/20, step 231/829, loss: 3.618817090988159\n",
      "Epoch 10/20, step 241/829, loss: 4.037609577178955\n",
      "Epoch 10/20, step 251/829, loss: 6.998154640197754\n",
      "Epoch 10/20, step 261/829, loss: 5.189321041107178\n",
      "Epoch 10/20, step 271/829, loss: 2.1036295890808105\n",
      "Epoch 10/20, step 281/829, loss: 3.025364398956299\n",
      "Epoch 10/20, step 291/829, loss: 5.707108020782471\n",
      "Epoch 10/20, step 301/829, loss: 5.823771953582764\n",
      "Epoch 10/20, step 311/829, loss: 1.3058910369873047\n",
      "Epoch 10/20, step 321/829, loss: 1.2465327978134155\n",
      "Epoch 10/20, step 331/829, loss: 0.970731794834137\n",
      "Epoch 10/20, step 341/829, loss: 13.16331672668457\n",
      "Epoch 10/20, step 351/829, loss: 3.883769989013672\n",
      "Epoch 10/20, step 361/829, loss: 5.316098690032959\n",
      "Epoch 10/20, step 371/829, loss: 2.2434253692626953\n",
      "Epoch 10/20, step 381/829, loss: 1.4321175813674927\n",
      "Epoch 10/20, step 391/829, loss: 4.558121204376221\n",
      "Epoch 10/20, step 401/829, loss: 2.186427593231201\n",
      "Epoch 10/20, step 411/829, loss: 5.421797752380371\n",
      "Epoch 10/20, step 421/829, loss: 3.460677146911621\n",
      "Epoch 10/20, step 431/829, loss: 21.77640724182129\n",
      "Epoch 10/20, step 441/829, loss: 8.485127449035645\n",
      "Epoch 10/20, step 451/829, loss: 1.721198558807373\n",
      "Epoch 10/20, step 461/829, loss: 11.300531387329102\n",
      "Epoch 10/20, step 471/829, loss: 1.9167505502700806\n",
      "Epoch 10/20, step 481/829, loss: 4.678433418273926\n",
      "Epoch 10/20, step 491/829, loss: 8.774773597717285\n",
      "Epoch 10/20, step 501/829, loss: 4.658366680145264\n",
      "Epoch 10/20, step 511/829, loss: 6.871085166931152\n",
      "Epoch 10/20, step 521/829, loss: 1.023380160331726\n",
      "Epoch 10/20, step 531/829, loss: 0.520393431186676\n",
      "Epoch 10/20, step 541/829, loss: 7.635173797607422\n",
      "Epoch 10/20, step 551/829, loss: 5.245821475982666\n",
      "Epoch 10/20, step 561/829, loss: 17.90288734436035\n",
      "Epoch 10/20, step 571/829, loss: 1.958707332611084\n",
      "Epoch 10/20, step 581/829, loss: 3.769395112991333\n",
      "Epoch 10/20, step 591/829, loss: 0.9471171498298645\n",
      "Epoch 10/20, step 601/829, loss: 249.45703125\n",
      "Epoch 10/20, step 611/829, loss: 3.6188385486602783\n",
      "Epoch 10/20, step 621/829, loss: 4.081174373626709\n",
      "Epoch 10/20, step 631/829, loss: 3.7194864749908447\n",
      "Epoch 10/20, step 641/829, loss: 3.0542662143707275\n",
      "Epoch 10/20, step 651/829, loss: 1.4375250339508057\n",
      "Epoch 10/20, step 661/829, loss: 6.009688377380371\n",
      "Epoch 10/20, step 671/829, loss: 2.244577407836914\n",
      "Epoch 10/20, step 681/829, loss: 3.6825015544891357\n",
      "Epoch 10/20, step 691/829, loss: 10.301895141601562\n",
      "Epoch 10/20, step 701/829, loss: 3.6231167316436768\n",
      "Epoch 10/20, step 711/829, loss: 1.762349247932434\n",
      "Epoch 10/20, step 721/829, loss: 10.748661041259766\n",
      "Epoch 10/20, step 731/829, loss: 6.350134372711182\n",
      "Epoch 10/20, step 741/829, loss: 17.549917221069336\n",
      "Epoch 10/20, step 751/829, loss: 7.302353382110596\n",
      "Epoch 10/20, step 761/829, loss: 73.7240219116211\n",
      "Epoch 10/20, step 771/829, loss: 3.9775478839874268\n",
      "Epoch 10/20, step 781/829, loss: 9.711160659790039\n",
      "Epoch 10/20, step 791/829, loss: 10.372260093688965\n",
      "Epoch 10/20, step 801/829, loss: 1.7717010974884033\n",
      "Epoch 10/20, step 811/829, loss: 14.672226905822754\n",
      "Epoch 10/20, step 821/829, loss: 4.366113662719727\n",
      "Epoch 11/20, step 1/829, loss: 9.49229907989502\n",
      "Epoch 11/20, step 11/829, loss: 4.3839335441589355\n",
      "Epoch 11/20, step 21/829, loss: 2.8473315238952637\n",
      "Epoch 11/20, step 31/829, loss: 13.711444854736328\n",
      "Epoch 11/20, step 41/829, loss: 3.095611810684204\n",
      "Epoch 11/20, step 51/829, loss: 3.538148880004883\n",
      "Epoch 11/20, step 61/829, loss: 0.7053627371788025\n",
      "Epoch 11/20, step 71/829, loss: 4.077226161956787\n",
      "Epoch 11/20, step 81/829, loss: 1.143345594406128\n",
      "Epoch 11/20, step 91/829, loss: 2.194662094116211\n",
      "Epoch 11/20, step 101/829, loss: 2.4284534454345703\n",
      "Epoch 11/20, step 111/829, loss: 1.4824455976486206\n",
      "Epoch 11/20, step 121/829, loss: 1.7044951915740967\n",
      "Epoch 11/20, step 131/829, loss: 4.322979927062988\n",
      "Epoch 11/20, step 141/829, loss: 1.354650855064392\n",
      "Epoch 11/20, step 151/829, loss: 8.936814308166504\n",
      "Epoch 11/20, step 161/829, loss: 6.594704627990723\n",
      "Epoch 11/20, step 171/829, loss: 3.3520357608795166\n",
      "Epoch 11/20, step 181/829, loss: 2.059196949005127\n",
      "Epoch 11/20, step 191/829, loss: 2.553823232650757\n",
      "Epoch 11/20, step 201/829, loss: 2.71604323387146\n",
      "Epoch 11/20, step 211/829, loss: 0.9394775629043579\n",
      "Epoch 11/20, step 221/829, loss: 1.9786276817321777\n",
      "Epoch 11/20, step 231/829, loss: 2.9861347675323486\n",
      "Epoch 11/20, step 241/829, loss: 3.46079158782959\n",
      "Epoch 11/20, step 251/829, loss: 3.684441328048706\n",
      "Epoch 11/20, step 261/829, loss: 2.314748525619507\n",
      "Epoch 11/20, step 271/829, loss: 1.533479928970337\n",
      "Epoch 11/20, step 281/829, loss: 4.817173957824707\n",
      "Epoch 11/20, step 291/829, loss: 2.9418880939483643\n",
      "Epoch 11/20, step 301/829, loss: 2.9665119647979736\n",
      "Epoch 11/20, step 311/829, loss: 2.987725019454956\n",
      "Epoch 11/20, step 321/829, loss: 1.7725365161895752\n",
      "Epoch 11/20, step 331/829, loss: 9.618192672729492\n",
      "Epoch 11/20, step 341/829, loss: 0.7889512777328491\n",
      "Epoch 11/20, step 351/829, loss: 2.2034034729003906\n",
      "Epoch 11/20, step 361/829, loss: 15.578781127929688\n",
      "Epoch 11/20, step 371/829, loss: 3.2998337745666504\n",
      "Epoch 11/20, step 381/829, loss: 10.513644218444824\n",
      "Epoch 11/20, step 391/829, loss: 5.732308864593506\n",
      "Epoch 11/20, step 401/829, loss: 2.9485671520233154\n",
      "Epoch 11/20, step 411/829, loss: 3.412477970123291\n",
      "Epoch 11/20, step 421/829, loss: 8.047189712524414\n",
      "Epoch 11/20, step 431/829, loss: 6.689960956573486\n",
      "Epoch 11/20, step 441/829, loss: 1.5811169147491455\n",
      "Epoch 11/20, step 451/829, loss: 5.418676853179932\n",
      "Epoch 11/20, step 461/829, loss: 3.2146291732788086\n",
      "Epoch 11/20, step 471/829, loss: 2.4183309078216553\n",
      "Epoch 11/20, step 481/829, loss: 1.418525218963623\n",
      "Epoch 11/20, step 491/829, loss: 0.7768779993057251\n",
      "Epoch 11/20, step 501/829, loss: 3.590649366378784\n",
      "Epoch 11/20, step 511/829, loss: 3.730510950088501\n",
      "Epoch 11/20, step 521/829, loss: 3.925065279006958\n",
      "Epoch 11/20, step 531/829, loss: 1.4181827306747437\n",
      "Epoch 11/20, step 541/829, loss: 1.6263372898101807\n",
      "Epoch 11/20, step 551/829, loss: 1.7332344055175781\n",
      "Epoch 11/20, step 561/829, loss: 1.5240238904953003\n",
      "Epoch 11/20, step 571/829, loss: 3.5196104049682617\n",
      "Epoch 11/20, step 581/829, loss: 1.0707942247390747\n",
      "Epoch 11/20, step 591/829, loss: 2.0845305919647217\n",
      "Epoch 11/20, step 601/829, loss: 1.273465633392334\n",
      "Epoch 11/20, step 611/829, loss: 2.3968422412872314\n",
      "Epoch 11/20, step 621/829, loss: 1.2638165950775146\n",
      "Epoch 11/20, step 631/829, loss: 1.1098350286483765\n",
      "Epoch 11/20, step 641/829, loss: 1.7920243740081787\n",
      "Epoch 11/20, step 651/829, loss: 1.5702720880508423\n",
      "Epoch 11/20, step 661/829, loss: 1.6839200258255005\n",
      "Epoch 11/20, step 671/829, loss: 1.1023013591766357\n",
      "Epoch 11/20, step 681/829, loss: 3.226264476776123\n",
      "Epoch 11/20, step 691/829, loss: 4.614808082580566\n",
      "Epoch 11/20, step 701/829, loss: 0.9680745601654053\n",
      "Epoch 11/20, step 711/829, loss: 2.93769907951355\n",
      "Epoch 11/20, step 721/829, loss: 6.211365699768066\n",
      "Epoch 11/20, step 731/829, loss: 4.543551445007324\n",
      "Epoch 11/20, step 741/829, loss: 14.243827819824219\n",
      "Epoch 11/20, step 751/829, loss: 2.644209384918213\n",
      "Epoch 11/20, step 761/829, loss: 3.872385263442993\n",
      "Epoch 11/20, step 771/829, loss: 1.8514562845230103\n",
      "Epoch 11/20, step 781/829, loss: 1.9344416856765747\n",
      "Epoch 11/20, step 791/829, loss: 2.6882481575012207\n",
      "Epoch 11/20, step 801/829, loss: 1.8172328472137451\n",
      "Epoch 11/20, step 811/829, loss: 5.285469055175781\n",
      "Epoch 11/20, step 821/829, loss: 2.0540671348571777\n",
      "Epoch 12/20, step 1/829, loss: 0.9070313572883606\n",
      "Epoch 12/20, step 11/829, loss: 2.4358010292053223\n",
      "Epoch 12/20, step 21/829, loss: 1.6650397777557373\n",
      "Epoch 12/20, step 31/829, loss: 1.8883731365203857\n",
      "Epoch 12/20, step 41/829, loss: 4.128554344177246\n",
      "Epoch 12/20, step 51/829, loss: 75.91839599609375\n",
      "Epoch 12/20, step 61/829, loss: 1.7381892204284668\n",
      "Epoch 12/20, step 71/829, loss: 2.9072985649108887\n",
      "Epoch 12/20, step 81/829, loss: 15.326218605041504\n",
      "Epoch 12/20, step 91/829, loss: 2.342454433441162\n",
      "Epoch 12/20, step 101/829, loss: 1.2972685098648071\n",
      "Epoch 12/20, step 111/829, loss: 2.553227424621582\n",
      "Epoch 12/20, step 121/829, loss: 1.153860092163086\n",
      "Epoch 12/20, step 131/829, loss: 1.288684606552124\n",
      "Epoch 12/20, step 141/829, loss: 2.10247802734375\n",
      "Epoch 12/20, step 151/829, loss: 1.7043229341506958\n",
      "Epoch 12/20, step 161/829, loss: 3.7302515506744385\n",
      "Epoch 12/20, step 171/829, loss: 5.882794380187988\n",
      "Epoch 12/20, step 181/829, loss: 1.8512405157089233\n",
      "Epoch 12/20, step 191/829, loss: 1.5319398641586304\n",
      "Epoch 12/20, step 201/829, loss: 1.1685339212417603\n",
      "Epoch 12/20, step 211/829, loss: 3.743360996246338\n",
      "Epoch 12/20, step 221/829, loss: 1.5193217992782593\n",
      "Epoch 12/20, step 231/829, loss: 1.7211800813674927\n",
      "Epoch 12/20, step 241/829, loss: 3.1725656986236572\n",
      "Epoch 12/20, step 251/829, loss: 1.5618798732757568\n",
      "Epoch 12/20, step 261/829, loss: 2.397481918334961\n",
      "Epoch 12/20, step 271/829, loss: 3.663752794265747\n",
      "Epoch 12/20, step 281/829, loss: 1.0776818990707397\n",
      "Epoch 12/20, step 291/829, loss: 77.34500885009766\n",
      "Epoch 12/20, step 301/829, loss: 3.848503828048706\n",
      "Epoch 12/20, step 311/829, loss: 2.2703702449798584\n",
      "Epoch 12/20, step 321/829, loss: 2.0991978645324707\n",
      "Epoch 12/20, step 331/829, loss: 10.674290657043457\n",
      "Epoch 12/20, step 341/829, loss: 2.1474010944366455\n",
      "Epoch 12/20, step 351/829, loss: 2.4027199745178223\n",
      "Epoch 12/20, step 361/829, loss: 4.247114181518555\n",
      "Epoch 12/20, step 371/829, loss: 2.2247350215911865\n",
      "Epoch 12/20, step 381/829, loss: 0.662320077419281\n",
      "Epoch 12/20, step 391/829, loss: 3.2673089504241943\n",
      "Epoch 12/20, step 401/829, loss: 2.1131179332733154\n",
      "Epoch 12/20, step 411/829, loss: 1.676604986190796\n",
      "Epoch 12/20, step 421/829, loss: 1.513985514640808\n",
      "Epoch 12/20, step 431/829, loss: 1.7119202613830566\n",
      "Epoch 12/20, step 441/829, loss: 1.2040901184082031\n",
      "Epoch 12/20, step 451/829, loss: 4.86288595199585\n",
      "Epoch 12/20, step 461/829, loss: 1.182527780532837\n",
      "Epoch 12/20, step 471/829, loss: 0.43916240334510803\n",
      "Epoch 12/20, step 481/829, loss: 1.307125449180603\n",
      "Epoch 12/20, step 491/829, loss: 5.947055339813232\n",
      "Epoch 12/20, step 501/829, loss: 1.5316029787063599\n",
      "Epoch 12/20, step 511/829, loss: 1.011683464050293\n",
      "Epoch 12/20, step 521/829, loss: 1.9951192140579224\n",
      "Epoch 12/20, step 531/829, loss: 1.2252262830734253\n",
      "Epoch 12/20, step 541/829, loss: 4.389298915863037\n",
      "Epoch 12/20, step 551/829, loss: 2.2086262702941895\n",
      "Epoch 12/20, step 561/829, loss: 4.531177520751953\n",
      "Epoch 12/20, step 571/829, loss: 1.7613651752471924\n",
      "Epoch 12/20, step 581/829, loss: 5.086368083953857\n",
      "Epoch 12/20, step 591/829, loss: 0.6769770383834839\n",
      "Epoch 12/20, step 601/829, loss: 2.968716621398926\n",
      "Epoch 12/20, step 611/829, loss: 1.5181254148483276\n",
      "Epoch 12/20, step 621/829, loss: 18.713003158569336\n",
      "Epoch 12/20, step 631/829, loss: 5.411835670471191\n",
      "Epoch 12/20, step 641/829, loss: 3.164121150970459\n",
      "Epoch 12/20, step 651/829, loss: 1.2845704555511475\n",
      "Epoch 12/20, step 661/829, loss: 5.148004055023193\n",
      "Epoch 12/20, step 671/829, loss: 1.3707311153411865\n",
      "Epoch 12/20, step 681/829, loss: 100.06204223632812\n",
      "Epoch 12/20, step 691/829, loss: 1.4219037294387817\n",
      "Epoch 12/20, step 701/829, loss: 1.529442310333252\n",
      "Epoch 12/20, step 711/829, loss: 1.3145822286605835\n",
      "Epoch 12/20, step 721/829, loss: 1.8023170232772827\n",
      "Epoch 12/20, step 731/829, loss: 1.1708052158355713\n",
      "Epoch 12/20, step 741/829, loss: 1.5121115446090698\n",
      "Epoch 12/20, step 751/829, loss: 1.2068803310394287\n",
      "Epoch 12/20, step 761/829, loss: 3.532266616821289\n",
      "Epoch 12/20, step 771/829, loss: 2.147517681121826\n",
      "Epoch 12/20, step 781/829, loss: 9.362113952636719\n",
      "Epoch 12/20, step 791/829, loss: 1.274749755859375\n",
      "Epoch 12/20, step 801/829, loss: 3.3371899127960205\n",
      "Epoch 12/20, step 811/829, loss: 1.4214268922805786\n",
      "Epoch 12/20, step 821/829, loss: 0.9688208699226379\n",
      "Epoch 13/20, step 1/829, loss: 1.7585082054138184\n",
      "Epoch 13/20, step 11/829, loss: 0.8571304678916931\n",
      "Epoch 13/20, step 21/829, loss: 1.4919180870056152\n",
      "Epoch 13/20, step 31/829, loss: 1.40524423122406\n",
      "Epoch 13/20, step 41/829, loss: 1.0744869709014893\n",
      "Epoch 13/20, step 51/829, loss: 2.0874626636505127\n",
      "Epoch 13/20, step 61/829, loss: 1.67949378490448\n",
      "Epoch 13/20, step 71/829, loss: 29.30686378479004\n",
      "Epoch 13/20, step 81/829, loss: 0.9366466403007507\n",
      "Epoch 13/20, step 91/829, loss: 1.8092044591903687\n",
      "Epoch 13/20, step 101/829, loss: 2.9490630626678467\n",
      "Epoch 13/20, step 111/829, loss: 2.3727452754974365\n",
      "Epoch 13/20, step 121/829, loss: 1.684424638748169\n",
      "Epoch 13/20, step 131/829, loss: 1.1406078338623047\n",
      "Epoch 13/20, step 141/829, loss: 1.7636518478393555\n",
      "Epoch 13/20, step 151/829, loss: 1.2756233215332031\n",
      "Epoch 13/20, step 161/829, loss: 2.872241497039795\n",
      "Epoch 13/20, step 171/829, loss: 0.9098466634750366\n",
      "Epoch 13/20, step 181/829, loss: 2.9908947944641113\n",
      "Epoch 13/20, step 191/829, loss: 1.4994256496429443\n",
      "Epoch 13/20, step 201/829, loss: 2.4370839595794678\n",
      "Epoch 13/20, step 211/829, loss: 2.473834753036499\n",
      "Epoch 13/20, step 221/829, loss: 9.146246910095215\n",
      "Epoch 13/20, step 231/829, loss: 76.3641586303711\n",
      "Epoch 13/20, step 241/829, loss: 142.0248260498047\n",
      "Epoch 13/20, step 251/829, loss: 33.125755310058594\n",
      "Epoch 13/20, step 261/829, loss: 3.34399151802063\n",
      "Epoch 13/20, step 271/829, loss: 5.311713695526123\n",
      "Epoch 13/20, step 281/829, loss: 2.7974259853363037\n",
      "Epoch 13/20, step 291/829, loss: 2.530763626098633\n",
      "Epoch 13/20, step 301/829, loss: 13.222333908081055\n",
      "Epoch 13/20, step 311/829, loss: 1.850500226020813\n",
      "Epoch 13/20, step 321/829, loss: 2.0013041496276855\n",
      "Epoch 13/20, step 331/829, loss: 1.969352126121521\n",
      "Epoch 13/20, step 341/829, loss: 2.4685235023498535\n",
      "Epoch 13/20, step 351/829, loss: 1.1937837600708008\n",
      "Epoch 13/20, step 361/829, loss: 9.79173755645752\n",
      "Epoch 13/20, step 371/829, loss: 1.449576735496521\n",
      "Epoch 13/20, step 381/829, loss: 1.9610934257507324\n",
      "Epoch 13/20, step 391/829, loss: 0.6482403874397278\n",
      "Epoch 13/20, step 401/829, loss: 3.195969820022583\n",
      "Epoch 13/20, step 411/829, loss: 117.64408111572266\n",
      "Epoch 13/20, step 421/829, loss: 2.697556257247925\n",
      "Epoch 13/20, step 431/829, loss: 2.4846622943878174\n",
      "Epoch 13/20, step 441/829, loss: 1.991563081741333\n",
      "Epoch 13/20, step 451/829, loss: 1.3282302618026733\n",
      "Epoch 13/20, step 461/829, loss: 13.346274375915527\n",
      "Epoch 13/20, step 471/829, loss: 0.5992116332054138\n",
      "Epoch 13/20, step 481/829, loss: 0.352190762758255\n",
      "Epoch 13/20, step 491/829, loss: 0.541443943977356\n",
      "Epoch 13/20, step 501/829, loss: 3.527139902114868\n",
      "Epoch 13/20, step 511/829, loss: 2.399531126022339\n",
      "Epoch 13/20, step 521/829, loss: 1.098806619644165\n",
      "Epoch 13/20, step 531/829, loss: 2.4113879203796387\n",
      "Epoch 13/20, step 541/829, loss: 1.8757812976837158\n",
      "Epoch 13/20, step 551/829, loss: 1.10830819606781\n",
      "Epoch 13/20, step 561/829, loss: 1.360217571258545\n",
      "Epoch 13/20, step 571/829, loss: 0.9694409370422363\n",
      "Epoch 13/20, step 581/829, loss: 2.025865077972412\n",
      "Epoch 13/20, step 591/829, loss: 0.876762866973877\n",
      "Epoch 13/20, step 601/829, loss: 2.594133138656616\n",
      "Epoch 13/20, step 611/829, loss: 0.995150089263916\n",
      "Epoch 13/20, step 621/829, loss: 0.7416713237762451\n",
      "Epoch 13/20, step 631/829, loss: 0.6431471109390259\n",
      "Epoch 13/20, step 641/829, loss: 0.6898210048675537\n",
      "Epoch 13/20, step 651/829, loss: 2.7503042221069336\n",
      "Epoch 13/20, step 661/829, loss: 0.380734384059906\n",
      "Epoch 13/20, step 671/829, loss: 4.492805004119873\n",
      "Epoch 13/20, step 681/829, loss: 1.0685148239135742\n",
      "Epoch 13/20, step 691/829, loss: 2.3080902099609375\n",
      "Epoch 13/20, step 701/829, loss: 38.91872024536133\n",
      "Epoch 13/20, step 711/829, loss: 2.7285149097442627\n",
      "Epoch 13/20, step 721/829, loss: 1.3850020170211792\n",
      "Epoch 13/20, step 731/829, loss: 1.1392457485198975\n",
      "Epoch 13/20, step 741/829, loss: 2.125427722930908\n",
      "Epoch 13/20, step 751/829, loss: 1.310368537902832\n",
      "Epoch 13/20, step 761/829, loss: 3.0234267711639404\n",
      "Epoch 13/20, step 771/829, loss: 21.779645919799805\n",
      "Epoch 13/20, step 781/829, loss: 8.31954574584961\n",
      "Epoch 13/20, step 791/829, loss: 2.6552252769470215\n",
      "Epoch 13/20, step 801/829, loss: 0.6421830058097839\n",
      "Epoch 13/20, step 811/829, loss: 2.4633870124816895\n",
      "Epoch 13/20, step 821/829, loss: 6.216003894805908\n",
      "Epoch 14/20, step 1/829, loss: 1.0968209505081177\n",
      "Epoch 14/20, step 11/829, loss: 11.52800464630127\n",
      "Epoch 14/20, step 21/829, loss: 1.2896493673324585\n",
      "Epoch 14/20, step 31/829, loss: 1.2722476720809937\n",
      "Epoch 14/20, step 41/829, loss: 5.157663345336914\n",
      "Epoch 14/20, step 51/829, loss: 1.5160499811172485\n",
      "Epoch 14/20, step 61/829, loss: 0.46122628450393677\n",
      "Epoch 14/20, step 71/829, loss: 17.910871505737305\n",
      "Epoch 14/20, step 81/829, loss: 4.183165550231934\n",
      "Epoch 14/20, step 91/829, loss: 6.754026412963867\n",
      "Epoch 14/20, step 101/829, loss: 2.444486379623413\n",
      "Epoch 14/20, step 111/829, loss: 0.8887444138526917\n",
      "Epoch 14/20, step 121/829, loss: 7.509653091430664\n",
      "Epoch 14/20, step 131/829, loss: 2.823463201522827\n",
      "Epoch 14/20, step 141/829, loss: 0.8380863070487976\n",
      "Epoch 14/20, step 151/829, loss: 1.230729103088379\n",
      "Epoch 14/20, step 161/829, loss: 1.3829896450042725\n",
      "Epoch 14/20, step 171/829, loss: 3.013341188430786\n",
      "Epoch 14/20, step 181/829, loss: 0.937188982963562\n",
      "Epoch 14/20, step 191/829, loss: 0.874345064163208\n",
      "Epoch 14/20, step 201/829, loss: 8.734922409057617\n",
      "Epoch 14/20, step 211/829, loss: 1.6851814985275269\n",
      "Epoch 14/20, step 221/829, loss: 5.6819939613342285\n",
      "Epoch 14/20, step 231/829, loss: 3.3861842155456543\n",
      "Epoch 14/20, step 241/829, loss: 2.545043468475342\n",
      "Epoch 14/20, step 251/829, loss: 2.468766450881958\n",
      "Epoch 14/20, step 261/829, loss: 5.316887855529785\n",
      "Epoch 14/20, step 271/829, loss: 14.728031158447266\n",
      "Epoch 14/20, step 281/829, loss: 8.463401794433594\n",
      "Epoch 14/20, step 291/829, loss: 1.6261439323425293\n",
      "Epoch 14/20, step 301/829, loss: 6.8614373207092285\n",
      "Epoch 14/20, step 311/829, loss: 5.11297607421875\n",
      "Epoch 14/20, step 321/829, loss: 93.55043029785156\n",
      "Epoch 14/20, step 331/829, loss: 1.0638312101364136\n",
      "Epoch 14/20, step 341/829, loss: 2.030362129211426\n",
      "Epoch 14/20, step 351/829, loss: 1.1797584295272827\n",
      "Epoch 14/20, step 361/829, loss: 1.1229166984558105\n",
      "Epoch 14/20, step 371/829, loss: 0.7273956537246704\n",
      "Epoch 14/20, step 381/829, loss: 6.437734603881836\n",
      "Epoch 14/20, step 391/829, loss: 1.4031901359558105\n",
      "Epoch 14/20, step 401/829, loss: 4.431009769439697\n",
      "Epoch 14/20, step 411/829, loss: 2.2201123237609863\n",
      "Epoch 14/20, step 421/829, loss: 4.010060787200928\n",
      "Epoch 14/20, step 431/829, loss: 1.9134154319763184\n",
      "Epoch 14/20, step 441/829, loss: 1.5661019086837769\n",
      "Epoch 14/20, step 451/829, loss: 1.2562698125839233\n",
      "Epoch 14/20, step 461/829, loss: 0.7059816718101501\n",
      "Epoch 14/20, step 471/829, loss: 2.3620426654815674\n",
      "Epoch 14/20, step 481/829, loss: 1.850897192955017\n",
      "Epoch 14/20, step 491/829, loss: 1.8329463005065918\n",
      "Epoch 14/20, step 501/829, loss: 1.1045254468917847\n",
      "Epoch 14/20, step 511/829, loss: 1.4772669076919556\n",
      "Epoch 14/20, step 521/829, loss: 98.30187225341797\n",
      "Epoch 14/20, step 531/829, loss: 1.632238745689392\n",
      "Epoch 14/20, step 541/829, loss: 2.214219808578491\n",
      "Epoch 14/20, step 551/829, loss: 2.0185513496398926\n",
      "Epoch 14/20, step 561/829, loss: 2.2913832664489746\n",
      "Epoch 14/20, step 571/829, loss: 2.3600196838378906\n",
      "Epoch 14/20, step 581/829, loss: 0.9476938247680664\n",
      "Epoch 14/20, step 591/829, loss: 1.9276700019836426\n",
      "Epoch 14/20, step 601/829, loss: 0.8362553715705872\n",
      "Epoch 14/20, step 611/829, loss: 0.5092947483062744\n",
      "Epoch 14/20, step 621/829, loss: 3.103506565093994\n",
      "Epoch 14/20, step 631/829, loss: 3.7493839263916016\n",
      "Epoch 14/20, step 641/829, loss: 2.148176670074463\n",
      "Epoch 14/20, step 651/829, loss: 2.4082729816436768\n",
      "Epoch 14/20, step 661/829, loss: 11.488056182861328\n",
      "Epoch 14/20, step 671/829, loss: 4.97803258895874\n",
      "Epoch 14/20, step 681/829, loss: 1.4302769899368286\n",
      "Epoch 14/20, step 691/829, loss: 1.702632188796997\n",
      "Epoch 14/20, step 701/829, loss: 6.717031955718994\n",
      "Epoch 14/20, step 711/829, loss: 0.7590698599815369\n",
      "Epoch 14/20, step 721/829, loss: 0.36470863223075867\n",
      "Epoch 14/20, step 731/829, loss: 1.19441556930542\n",
      "Epoch 14/20, step 741/829, loss: 0.6706960201263428\n",
      "Epoch 14/20, step 751/829, loss: 1.853926181793213\n",
      "Epoch 14/20, step 761/829, loss: 1.2676141262054443\n",
      "Epoch 14/20, step 771/829, loss: 2.411856174468994\n",
      "Epoch 14/20, step 781/829, loss: 1.7001652717590332\n",
      "Epoch 14/20, step 791/829, loss: 2.5216481685638428\n",
      "Epoch 14/20, step 801/829, loss: 11.73837661743164\n",
      "Epoch 14/20, step 811/829, loss: 0.5042295455932617\n",
      "Epoch 14/20, step 821/829, loss: 8.324030876159668\n",
      "Epoch 15/20, step 1/829, loss: 1.306005835533142\n",
      "Epoch 15/20, step 11/829, loss: 1.3530552387237549\n",
      "Epoch 15/20, step 21/829, loss: 1.262630820274353\n",
      "Epoch 15/20, step 31/829, loss: 1.4969991445541382\n",
      "Epoch 15/20, step 41/829, loss: 0.8499334454536438\n",
      "Epoch 15/20, step 51/829, loss: 28.701030731201172\n",
      "Epoch 15/20, step 61/829, loss: 0.8182674646377563\n",
      "Epoch 15/20, step 71/829, loss: 1.3000023365020752\n",
      "Epoch 15/20, step 81/829, loss: 5.568078994750977\n",
      "Epoch 15/20, step 91/829, loss: 1.900451421737671\n",
      "Epoch 15/20, step 101/829, loss: 1.802228331565857\n",
      "Epoch 15/20, step 111/829, loss: 1.915311336517334\n",
      "Epoch 15/20, step 121/829, loss: 1.7752645015716553\n",
      "Epoch 15/20, step 131/829, loss: 2.5681378841400146\n",
      "Epoch 15/20, step 141/829, loss: 67.34942626953125\n",
      "Epoch 15/20, step 151/829, loss: 1.4205701351165771\n",
      "Epoch 15/20, step 161/829, loss: 1.3554623126983643\n",
      "Epoch 15/20, step 171/829, loss: 0.8258829712867737\n",
      "Epoch 15/20, step 181/829, loss: 0.9532375931739807\n",
      "Epoch 15/20, step 191/829, loss: 0.8906509280204773\n",
      "Epoch 15/20, step 201/829, loss: 1.337046504020691\n",
      "Epoch 15/20, step 211/829, loss: 0.4417687952518463\n",
      "Epoch 15/20, step 221/829, loss: 0.9809677600860596\n",
      "Epoch 15/20, step 231/829, loss: 0.7238967418670654\n",
      "Epoch 15/20, step 241/829, loss: 2.8993678092956543\n",
      "Epoch 15/20, step 251/829, loss: 1.591395616531372\n",
      "Epoch 15/20, step 261/829, loss: 0.5928290486335754\n",
      "Epoch 15/20, step 271/829, loss: 15.459473609924316\n",
      "Epoch 15/20, step 281/829, loss: 1.2224525213241577\n",
      "Epoch 15/20, step 291/829, loss: 0.706304132938385\n",
      "Epoch 15/20, step 301/829, loss: 1.6534407138824463\n",
      "Epoch 15/20, step 311/829, loss: 1.9213273525238037\n",
      "Epoch 15/20, step 321/829, loss: 1.2549896240234375\n",
      "Epoch 15/20, step 331/829, loss: 1.495093584060669\n",
      "Epoch 15/20, step 341/829, loss: 2.378560781478882\n",
      "Epoch 15/20, step 351/829, loss: 3.047003984451294\n",
      "Epoch 15/20, step 361/829, loss: 1.3022091388702393\n",
      "Epoch 15/20, step 371/829, loss: 1.6229023933410645\n",
      "Epoch 15/20, step 381/829, loss: 1.0335444211959839\n",
      "Epoch 15/20, step 391/829, loss: 3.083395481109619\n",
      "Epoch 15/20, step 401/829, loss: 40.6851921081543\n",
      "Epoch 15/20, step 411/829, loss: 2.181455612182617\n",
      "Epoch 15/20, step 421/829, loss: 1.1577792167663574\n",
      "Epoch 15/20, step 431/829, loss: 1.2868409156799316\n",
      "Epoch 15/20, step 441/829, loss: 2.2874808311462402\n",
      "Epoch 15/20, step 451/829, loss: 0.5920979380607605\n",
      "Epoch 15/20, step 461/829, loss: 3.0157456398010254\n",
      "Epoch 15/20, step 471/829, loss: 3.223623752593994\n",
      "Epoch 15/20, step 481/829, loss: 1.8352495431900024\n",
      "Epoch 15/20, step 491/829, loss: 2.990103244781494\n",
      "Epoch 15/20, step 501/829, loss: 0.8808447122573853\n",
      "Epoch 15/20, step 511/829, loss: 0.960750162601471\n",
      "Epoch 15/20, step 521/829, loss: 2.9249160289764404\n",
      "Epoch 15/20, step 531/829, loss: 1.5787289142608643\n",
      "Epoch 15/20, step 541/829, loss: 0.7981484532356262\n",
      "Epoch 15/20, step 551/829, loss: 0.45528268814086914\n",
      "Epoch 15/20, step 561/829, loss: 1.3220068216323853\n",
      "Epoch 15/20, step 571/829, loss: 1.3321833610534668\n",
      "Epoch 15/20, step 581/829, loss: 22.114112854003906\n",
      "Epoch 15/20, step 591/829, loss: 1.1892248392105103\n",
      "Epoch 15/20, step 601/829, loss: 1.0574100017547607\n",
      "Epoch 15/20, step 611/829, loss: 2.9357104301452637\n",
      "Epoch 15/20, step 621/829, loss: 5.78093957901001\n",
      "Epoch 15/20, step 631/829, loss: 0.7915035486221313\n",
      "Epoch 15/20, step 641/829, loss: 1.120901107788086\n",
      "Epoch 15/20, step 651/829, loss: 1.1728978157043457\n",
      "Epoch 15/20, step 661/829, loss: 6.702256679534912\n",
      "Epoch 15/20, step 671/829, loss: 12.052766799926758\n",
      "Epoch 15/20, step 681/829, loss: 2.6875712871551514\n",
      "Epoch 15/20, step 691/829, loss: 1.7669013738632202\n",
      "Epoch 15/20, step 701/829, loss: 1.3870787620544434\n",
      "Epoch 15/20, step 711/829, loss: 2.401866912841797\n",
      "Epoch 15/20, step 721/829, loss: 1.6416945457458496\n",
      "Epoch 15/20, step 731/829, loss: 1.6348615884780884\n",
      "Epoch 15/20, step 741/829, loss: 1.202939510345459\n",
      "Epoch 15/20, step 751/829, loss: 1.0122092962265015\n",
      "Epoch 15/20, step 761/829, loss: 0.6798087954521179\n",
      "Epoch 15/20, step 771/829, loss: 5.432013511657715\n",
      "Epoch 15/20, step 781/829, loss: 1.0879943370819092\n",
      "Epoch 15/20, step 791/829, loss: 1.3923362493515015\n",
      "Epoch 15/20, step 801/829, loss: 1.4229484796524048\n",
      "Epoch 15/20, step 811/829, loss: 2.010002851486206\n",
      "Epoch 15/20, step 821/829, loss: 16.048555374145508\n",
      "Epoch 16/20, step 1/829, loss: 1.353770136833191\n",
      "Epoch 16/20, step 11/829, loss: 5.924299240112305\n",
      "Epoch 16/20, step 21/829, loss: 3.010237216949463\n",
      "Epoch 16/20, step 31/829, loss: 0.7939473986625671\n",
      "Epoch 16/20, step 41/829, loss: 1.693137288093567\n",
      "Epoch 16/20, step 51/829, loss: 1.9490681886672974\n",
      "Epoch 16/20, step 61/829, loss: 1.1291823387145996\n",
      "Epoch 16/20, step 71/829, loss: 3.4277377128601074\n",
      "Epoch 16/20, step 81/829, loss: 2.3625195026397705\n",
      "Epoch 16/20, step 91/829, loss: 3.489501476287842\n",
      "Epoch 16/20, step 101/829, loss: 0.8083317875862122\n",
      "Epoch 16/20, step 111/829, loss: 1.7024095058441162\n",
      "Epoch 16/20, step 121/829, loss: 1.0189179182052612\n",
      "Epoch 16/20, step 131/829, loss: 1.1694505214691162\n",
      "Epoch 16/20, step 141/829, loss: 1.2388092279434204\n",
      "Epoch 16/20, step 151/829, loss: 0.6682115793228149\n",
      "Epoch 16/20, step 161/829, loss: 0.6963064074516296\n",
      "Epoch 16/20, step 171/829, loss: 0.6461559534072876\n",
      "Epoch 16/20, step 181/829, loss: 1.9033465385437012\n",
      "Epoch 16/20, step 191/829, loss: 3.0979816913604736\n",
      "Epoch 16/20, step 201/829, loss: 3.429079294204712\n",
      "Epoch 16/20, step 211/829, loss: 2.3871700763702393\n",
      "Epoch 16/20, step 221/829, loss: 1.0454257726669312\n",
      "Epoch 16/20, step 231/829, loss: 2.7506954669952393\n",
      "Epoch 16/20, step 241/829, loss: 4.6734299659729\n",
      "Epoch 16/20, step 251/829, loss: 1.484760046005249\n",
      "Epoch 16/20, step 261/829, loss: 3.0394341945648193\n",
      "Epoch 16/20, step 271/829, loss: 0.9811795949935913\n",
      "Epoch 16/20, step 281/829, loss: 0.747848391532898\n",
      "Epoch 16/20, step 291/829, loss: 0.839143693447113\n",
      "Epoch 16/20, step 301/829, loss: 2.124863624572754\n",
      "Epoch 16/20, step 311/829, loss: 3.017005681991577\n",
      "Epoch 16/20, step 321/829, loss: 0.7025007605552673\n",
      "Epoch 16/20, step 331/829, loss: 0.9692862033843994\n",
      "Epoch 16/20, step 341/829, loss: 0.9418182969093323\n",
      "Epoch 16/20, step 351/829, loss: 0.8499255776405334\n",
      "Epoch 16/20, step 361/829, loss: 0.814159095287323\n",
      "Epoch 16/20, step 371/829, loss: 2.185333728790283\n",
      "Epoch 16/20, step 381/829, loss: 1.678361415863037\n",
      "Epoch 16/20, step 391/829, loss: 1.66948401927948\n",
      "Epoch 16/20, step 401/829, loss: 2.2295315265655518\n",
      "Epoch 16/20, step 411/829, loss: 1.3522855043411255\n",
      "Epoch 16/20, step 421/829, loss: 14.87100601196289\n",
      "Epoch 16/20, step 431/829, loss: 1.1448544263839722\n",
      "Epoch 16/20, step 441/829, loss: 2.8394370079040527\n",
      "Epoch 16/20, step 451/829, loss: 90.82823944091797\n",
      "Epoch 16/20, step 461/829, loss: 1.055031180381775\n",
      "Epoch 16/20, step 471/829, loss: 2.126112699508667\n",
      "Epoch 16/20, step 481/829, loss: 1.1760914325714111\n",
      "Epoch 16/20, step 491/829, loss: 1.5421894788742065\n",
      "Epoch 16/20, step 501/829, loss: 2.5496232509613037\n",
      "Epoch 16/20, step 511/829, loss: 0.5374488234519958\n",
      "Epoch 16/20, step 521/829, loss: 1.8944000005722046\n",
      "Epoch 16/20, step 531/829, loss: 0.9077207446098328\n",
      "Epoch 16/20, step 541/829, loss: 0.7825918793678284\n",
      "Epoch 16/20, step 551/829, loss: 1.564256191253662\n",
      "Epoch 16/20, step 561/829, loss: 2.1109707355499268\n",
      "Epoch 16/20, step 571/829, loss: 0.9642044305801392\n",
      "Epoch 16/20, step 581/829, loss: 0.8941189050674438\n",
      "Epoch 16/20, step 591/829, loss: 1.596482515335083\n",
      "Epoch 16/20, step 601/829, loss: 2.0952820777893066\n",
      "Epoch 16/20, step 611/829, loss: 0.7995519042015076\n",
      "Epoch 16/20, step 621/829, loss: 50.21729278564453\n",
      "Epoch 16/20, step 631/829, loss: 1.0376033782958984\n",
      "Epoch 16/20, step 641/829, loss: 1.3835943937301636\n",
      "Epoch 16/20, step 651/829, loss: 0.1940668672323227\n",
      "Epoch 16/20, step 661/829, loss: 3.093609571456909\n",
      "Epoch 16/20, step 671/829, loss: 8.465716361999512\n",
      "Epoch 16/20, step 681/829, loss: 0.7306045293807983\n",
      "Epoch 16/20, step 691/829, loss: 0.5433414578437805\n",
      "Epoch 16/20, step 701/829, loss: 1.4360684156417847\n",
      "Epoch 16/20, step 711/829, loss: 0.9035341143608093\n",
      "Epoch 16/20, step 721/829, loss: 3.430929183959961\n",
      "Epoch 16/20, step 731/829, loss: 0.8269118070602417\n",
      "Epoch 16/20, step 741/829, loss: 2.77213716506958\n",
      "Epoch 16/20, step 751/829, loss: 0.8706729412078857\n",
      "Epoch 16/20, step 761/829, loss: 0.4734622538089752\n",
      "Epoch 16/20, step 771/829, loss: 0.7621013522148132\n",
      "Epoch 16/20, step 781/829, loss: 0.5249320268630981\n",
      "Epoch 16/20, step 791/829, loss: 0.9088671803474426\n",
      "Epoch 16/20, step 801/829, loss: 0.7499663233757019\n",
      "Epoch 16/20, step 811/829, loss: 14.499909400939941\n",
      "Epoch 16/20, step 821/829, loss: 0.5962371230125427\n",
      "Epoch 17/20, step 1/829, loss: 1.0305362939834595\n",
      "Epoch 17/20, step 11/829, loss: 1.931667685508728\n",
      "Epoch 17/20, step 21/829, loss: 0.5052942633628845\n",
      "Epoch 17/20, step 31/829, loss: 1.5169399976730347\n",
      "Epoch 17/20, step 41/829, loss: 0.5532782077789307\n",
      "Epoch 17/20, step 51/829, loss: 2.526639699935913\n",
      "Epoch 17/20, step 61/829, loss: 1.261561632156372\n",
      "Epoch 17/20, step 71/829, loss: 2.789185047149658\n",
      "Epoch 17/20, step 81/829, loss: 0.9227525591850281\n",
      "Epoch 17/20, step 91/829, loss: 0.8850338459014893\n",
      "Epoch 17/20, step 101/829, loss: 2.928215742111206\n",
      "Epoch 17/20, step 111/829, loss: 21.488794326782227\n",
      "Epoch 17/20, step 121/829, loss: 1.0401175022125244\n",
      "Epoch 17/20, step 131/829, loss: 0.32450026273727417\n",
      "Epoch 17/20, step 141/829, loss: 63.20526885986328\n",
      "Epoch 17/20, step 151/829, loss: 0.7989845871925354\n",
      "Epoch 17/20, step 161/829, loss: 1.1306287050247192\n",
      "Epoch 17/20, step 171/829, loss: 1.0229718685150146\n",
      "Epoch 17/20, step 181/829, loss: 1.3299239873886108\n",
      "Epoch 17/20, step 191/829, loss: 0.8521483540534973\n",
      "Epoch 17/20, step 201/829, loss: 0.5417900085449219\n",
      "Epoch 17/20, step 211/829, loss: 0.44971731305122375\n",
      "Epoch 17/20, step 221/829, loss: 0.7751591205596924\n",
      "Epoch 17/20, step 231/829, loss: 0.37639540433883667\n",
      "Epoch 17/20, step 241/829, loss: 0.6397417783737183\n",
      "Epoch 17/20, step 251/829, loss: 1.1516560316085815\n",
      "Epoch 17/20, step 261/829, loss: 1.1415928602218628\n",
      "Epoch 17/20, step 271/829, loss: 1.221495509147644\n",
      "Epoch 17/20, step 281/829, loss: 0.7924920916557312\n",
      "Epoch 17/20, step 291/829, loss: 0.848271906375885\n",
      "Epoch 17/20, step 301/829, loss: 0.6918535828590393\n",
      "Epoch 17/20, step 311/829, loss: 1.1834419965744019\n",
      "Epoch 17/20, step 321/829, loss: 1.408971905708313\n",
      "Epoch 17/20, step 331/829, loss: 0.6607353687286377\n",
      "Epoch 17/20, step 341/829, loss: 0.9573200941085815\n",
      "Epoch 17/20, step 351/829, loss: 0.6209543943405151\n",
      "Epoch 17/20, step 361/829, loss: 0.49726685881614685\n",
      "Epoch 17/20, step 371/829, loss: 1.07648503780365\n",
      "Epoch 17/20, step 381/829, loss: 2.6899824142456055\n",
      "Epoch 17/20, step 391/829, loss: 1.6113412380218506\n",
      "Epoch 17/20, step 401/829, loss: 0.47854214906692505\n",
      "Epoch 17/20, step 411/829, loss: 0.5250107049942017\n",
      "Epoch 17/20, step 421/829, loss: 4.404482364654541\n",
      "Epoch 17/20, step 431/829, loss: 1.5760735273361206\n",
      "Epoch 17/20, step 441/829, loss: 0.2754392921924591\n",
      "Epoch 17/20, step 451/829, loss: 9.377685546875\n",
      "Epoch 17/20, step 461/829, loss: 1.3229528665542603\n",
      "Epoch 17/20, step 471/829, loss: 1.6248154640197754\n",
      "Epoch 17/20, step 481/829, loss: 1.8870235681533813\n",
      "Epoch 17/20, step 491/829, loss: 1.6505522727966309\n",
      "Epoch 17/20, step 501/829, loss: 1.5931086540222168\n",
      "Epoch 17/20, step 511/829, loss: 1.0662038326263428\n",
      "Epoch 17/20, step 521/829, loss: 0.5729510188102722\n",
      "Epoch 17/20, step 531/829, loss: 0.8859110474586487\n",
      "Epoch 17/20, step 541/829, loss: 1.4577909708023071\n",
      "Epoch 17/20, step 551/829, loss: 3.024742603302002\n",
      "Epoch 17/20, step 561/829, loss: 3.4303784370422363\n",
      "Epoch 17/20, step 571/829, loss: 1.3754602670669556\n",
      "Epoch 17/20, step 581/829, loss: 0.7252791523933411\n",
      "Epoch 17/20, step 591/829, loss: 0.9963520765304565\n",
      "Epoch 17/20, step 601/829, loss: 0.3312970697879791\n",
      "Epoch 17/20, step 611/829, loss: 0.9223641157150269\n",
      "Epoch 17/20, step 621/829, loss: 1.827193021774292\n",
      "Epoch 17/20, step 631/829, loss: 2.021573066711426\n",
      "Epoch 17/20, step 641/829, loss: 2.1368815898895264\n",
      "Epoch 17/20, step 651/829, loss: 1.9200292825698853\n",
      "Epoch 17/20, step 661/829, loss: 0.6874397397041321\n",
      "Epoch 17/20, step 671/829, loss: 0.47747018933296204\n",
      "Epoch 17/20, step 681/829, loss: 1.90986967086792\n",
      "Epoch 17/20, step 691/829, loss: 3.9439666271209717\n",
      "Epoch 17/20, step 701/829, loss: 2.6101691722869873\n",
      "Epoch 17/20, step 711/829, loss: 3.4861538410186768\n",
      "Epoch 17/20, step 721/829, loss: 1.0607762336730957\n",
      "Epoch 17/20, step 731/829, loss: 1.9581899642944336\n",
      "Epoch 17/20, step 741/829, loss: 3.196362018585205\n",
      "Epoch 17/20, step 751/829, loss: 1.979863166809082\n",
      "Epoch 17/20, step 761/829, loss: 1.480518102645874\n",
      "Epoch 17/20, step 771/829, loss: 54.276981353759766\n",
      "Epoch 17/20, step 781/829, loss: 1.3812241554260254\n",
      "Epoch 17/20, step 791/829, loss: 2.043121814727783\n",
      "Epoch 17/20, step 801/829, loss: 2.06148624420166\n",
      "Epoch 17/20, step 811/829, loss: 1.7553220987319946\n",
      "Epoch 17/20, step 821/829, loss: 2.1473281383514404\n",
      "Epoch 18/20, step 1/829, loss: 2.2615411281585693\n",
      "Epoch 18/20, step 11/829, loss: 1.297994613647461\n",
      "Epoch 18/20, step 21/829, loss: 0.535591721534729\n",
      "Epoch 18/20, step 31/829, loss: 0.5876509547233582\n",
      "Epoch 18/20, step 41/829, loss: 0.8692175149917603\n",
      "Epoch 18/20, step 51/829, loss: 0.5314667224884033\n",
      "Epoch 18/20, step 61/829, loss: 0.7235685586929321\n",
      "Epoch 18/20, step 71/829, loss: 0.3625706136226654\n",
      "Epoch 18/20, step 81/829, loss: 1.8322432041168213\n",
      "Epoch 18/20, step 91/829, loss: 0.7970073223114014\n",
      "Epoch 18/20, step 101/829, loss: 1.0773295164108276\n",
      "Epoch 18/20, step 111/829, loss: 1.216663122177124\n",
      "Epoch 18/20, step 121/829, loss: 1.0204505920410156\n",
      "Epoch 18/20, step 131/829, loss: 1.2156676054000854\n",
      "Epoch 18/20, step 141/829, loss: 0.5805352330207825\n",
      "Epoch 18/20, step 151/829, loss: 1.1222213506698608\n",
      "Epoch 18/20, step 161/829, loss: 0.8087989687919617\n",
      "Epoch 18/20, step 171/829, loss: 0.8460093140602112\n",
      "Epoch 18/20, step 181/829, loss: 12.755356788635254\n",
      "Epoch 18/20, step 191/829, loss: 2.6586978435516357\n",
      "Epoch 18/20, step 201/829, loss: 4.062798500061035\n",
      "Epoch 18/20, step 211/829, loss: 19.447662353515625\n",
      "Epoch 18/20, step 221/829, loss: 2.1735339164733887\n",
      "Epoch 18/20, step 231/829, loss: 0.8160219788551331\n",
      "Epoch 18/20, step 241/829, loss: 0.7630264163017273\n",
      "Epoch 18/20, step 251/829, loss: 0.6439568996429443\n",
      "Epoch 18/20, step 261/829, loss: 0.7165175676345825\n",
      "Epoch 18/20, step 271/829, loss: 0.8759695291519165\n",
      "Epoch 18/20, step 281/829, loss: 1.4272980690002441\n",
      "Epoch 18/20, step 291/829, loss: 3.171369791030884\n",
      "Epoch 18/20, step 301/829, loss: 4.6397881507873535\n",
      "Epoch 18/20, step 311/829, loss: 2.053635835647583\n",
      "Epoch 18/20, step 321/829, loss: 1.5187218189239502\n",
      "Epoch 18/20, step 331/829, loss: 1.5970158576965332\n",
      "Epoch 18/20, step 341/829, loss: 0.7864352464675903\n",
      "Epoch 18/20, step 351/829, loss: 2.428439140319824\n",
      "Epoch 18/20, step 361/829, loss: 0.38878333568573\n",
      "Epoch 18/20, step 371/829, loss: 0.6474112272262573\n",
      "Epoch 18/20, step 381/829, loss: 0.6713197231292725\n",
      "Epoch 18/20, step 391/829, loss: 0.9711883068084717\n",
      "Epoch 18/20, step 401/829, loss: 1.1235389709472656\n",
      "Epoch 18/20, step 411/829, loss: 0.9698559045791626\n",
      "Epoch 18/20, step 421/829, loss: 0.3675454258918762\n",
      "Epoch 18/20, step 431/829, loss: 0.8280231356620789\n",
      "Epoch 18/20, step 441/829, loss: 0.911827564239502\n",
      "Epoch 18/20, step 451/829, loss: 2.530238628387451\n",
      "Epoch 18/20, step 461/829, loss: 2.468205213546753\n",
      "Epoch 18/20, step 471/829, loss: 0.7151197791099548\n",
      "Epoch 18/20, step 481/829, loss: 3.0988547801971436\n",
      "Epoch 18/20, step 491/829, loss: 1.2145612239837646\n",
      "Epoch 18/20, step 501/829, loss: 0.9411158561706543\n",
      "Epoch 18/20, step 511/829, loss: 3.562094211578369\n",
      "Epoch 18/20, step 521/829, loss: 2.0274243354797363\n",
      "Epoch 18/20, step 531/829, loss: 3.6728639602661133\n",
      "Epoch 18/20, step 541/829, loss: 4.486541748046875\n",
      "Epoch 18/20, step 551/829, loss: 1.7353088855743408\n",
      "Epoch 18/20, step 561/829, loss: 1.4821282625198364\n",
      "Epoch 18/20, step 571/829, loss: 0.9773102402687073\n",
      "Epoch 18/20, step 581/829, loss: 8.815576553344727\n",
      "Epoch 18/20, step 591/829, loss: 3.198212146759033\n",
      "Epoch 18/20, step 601/829, loss: 5.838740825653076\n",
      "Epoch 18/20, step 611/829, loss: 1.9791146516799927\n",
      "Epoch 18/20, step 621/829, loss: 4.95399284362793\n",
      "Epoch 18/20, step 631/829, loss: 1.098741888999939\n",
      "Epoch 18/20, step 641/829, loss: 0.8868197202682495\n",
      "Epoch 18/20, step 651/829, loss: 0.3593220114707947\n",
      "Epoch 18/20, step 661/829, loss: 0.6467966437339783\n",
      "Epoch 18/20, step 671/829, loss: 0.926690936088562\n",
      "Epoch 18/20, step 681/829, loss: 0.4698890149593353\n",
      "Epoch 18/20, step 691/829, loss: 0.3693276047706604\n",
      "Epoch 18/20, step 701/829, loss: 0.7920709848403931\n",
      "Epoch 18/20, step 711/829, loss: 1.1232397556304932\n",
      "Epoch 18/20, step 721/829, loss: 1.3728270530700684\n",
      "Epoch 18/20, step 731/829, loss: 2.2653934955596924\n",
      "Epoch 18/20, step 741/829, loss: 40.71607971191406\n",
      "Epoch 18/20, step 751/829, loss: 0.6173718571662903\n",
      "Epoch 18/20, step 761/829, loss: 0.8674368858337402\n",
      "Epoch 18/20, step 771/829, loss: 1.5742123126983643\n",
      "Epoch 18/20, step 781/829, loss: 2.8977677822113037\n",
      "Epoch 18/20, step 791/829, loss: 0.7144338488578796\n",
      "Epoch 18/20, step 801/829, loss: 0.5172871351242065\n",
      "Epoch 18/20, step 811/829, loss: 1.91181218624115\n",
      "Epoch 18/20, step 821/829, loss: 1.4752224683761597\n",
      "Epoch 19/20, step 1/829, loss: 0.35213378071784973\n",
      "Epoch 19/20, step 11/829, loss: 16.566383361816406\n",
      "Epoch 19/20, step 21/829, loss: 0.9123184680938721\n",
      "Epoch 19/20, step 31/829, loss: 0.8578642010688782\n",
      "Epoch 19/20, step 41/829, loss: 1.4128873348236084\n",
      "Epoch 19/20, step 51/829, loss: 2.1459062099456787\n",
      "Epoch 19/20, step 61/829, loss: 0.7900464534759521\n",
      "Epoch 19/20, step 71/829, loss: 0.22495563328266144\n",
      "Epoch 19/20, step 81/829, loss: 0.41547244787216187\n",
      "Epoch 19/20, step 91/829, loss: 1.5150151252746582\n",
      "Epoch 19/20, step 101/829, loss: 0.8047526478767395\n",
      "Epoch 19/20, step 111/829, loss: 1.8198237419128418\n",
      "Epoch 19/20, step 121/829, loss: 1.345882534980774\n",
      "Epoch 19/20, step 131/829, loss: 1.2326380014419556\n",
      "Epoch 19/20, step 141/829, loss: 0.6653145551681519\n",
      "Epoch 19/20, step 151/829, loss: 0.9565861821174622\n",
      "Epoch 19/20, step 161/829, loss: 1.9845432043075562\n",
      "Epoch 19/20, step 171/829, loss: 0.4457927644252777\n",
      "Epoch 19/20, step 181/829, loss: 424.31378173828125\n",
      "Epoch 19/20, step 191/829, loss: 13.563448905944824\n",
      "Epoch 19/20, step 201/829, loss: 3.7717936038970947\n",
      "Epoch 19/20, step 211/829, loss: 1.4271292686462402\n",
      "Epoch 19/20, step 221/829, loss: 1.6440279483795166\n",
      "Epoch 19/20, step 231/829, loss: 1.8010263442993164\n",
      "Epoch 19/20, step 241/829, loss: 2.4197959899902344\n",
      "Epoch 19/20, step 251/829, loss: 1.9475346803665161\n",
      "Epoch 19/20, step 261/829, loss: 4.2242608070373535\n",
      "Epoch 19/20, step 271/829, loss: 1.5771183967590332\n",
      "Epoch 19/20, step 281/829, loss: 22.33978843688965\n",
      "Epoch 19/20, step 291/829, loss: 4.110672473907471\n",
      "Epoch 19/20, step 301/829, loss: 1.2842148542404175\n",
      "Epoch 19/20, step 311/829, loss: 2.2268424034118652\n",
      "Epoch 19/20, step 321/829, loss: 0.7893604636192322\n",
      "Epoch 19/20, step 331/829, loss: 1.210100531578064\n",
      "Epoch 19/20, step 341/829, loss: 1.8507810831069946\n",
      "Epoch 19/20, step 351/829, loss: 1.6492162942886353\n",
      "Epoch 19/20, step 361/829, loss: 3.1598753929138184\n",
      "Epoch 19/20, step 371/829, loss: 1.1927366256713867\n",
      "Epoch 19/20, step 381/829, loss: 2.0056872367858887\n",
      "Epoch 19/20, step 391/829, loss: 0.9067441821098328\n",
      "Epoch 19/20, step 401/829, loss: 0.7290593385696411\n",
      "Epoch 19/20, step 411/829, loss: 2.045029878616333\n",
      "Epoch 19/20, step 421/829, loss: 3.259392499923706\n",
      "Epoch 19/20, step 431/829, loss: 2.0047414302825928\n",
      "Epoch 19/20, step 441/829, loss: 1.299107313156128\n",
      "Epoch 19/20, step 451/829, loss: 0.6141058802604675\n",
      "Epoch 19/20, step 461/829, loss: 0.8841233849525452\n",
      "Epoch 19/20, step 471/829, loss: 1.4531501531600952\n",
      "Epoch 19/20, step 481/829, loss: 0.9931647777557373\n",
      "Epoch 19/20, step 491/829, loss: 0.7270367741584778\n",
      "Epoch 19/20, step 501/829, loss: 2.3891656398773193\n",
      "Epoch 19/20, step 511/829, loss: 0.4168696999549866\n",
      "Epoch 19/20, step 521/829, loss: 0.5715476870536804\n",
      "Epoch 19/20, step 531/829, loss: 0.6812525391578674\n",
      "Epoch 19/20, step 541/829, loss: 1.5135079622268677\n",
      "Epoch 19/20, step 551/829, loss: 27.362634658813477\n",
      "Epoch 19/20, step 561/829, loss: 0.5336229801177979\n",
      "Epoch 19/20, step 571/829, loss: 0.5868625640869141\n",
      "Epoch 19/20, step 581/829, loss: 0.6273096203804016\n",
      "Epoch 19/20, step 591/829, loss: 0.5751103162765503\n",
      "Epoch 19/20, step 601/829, loss: 2.082343339920044\n",
      "Epoch 19/20, step 611/829, loss: 0.8896923065185547\n",
      "Epoch 19/20, step 621/829, loss: 1.0255639553070068\n",
      "Epoch 19/20, step 631/829, loss: 0.8550927042961121\n",
      "Epoch 19/20, step 641/829, loss: 2.1204335689544678\n",
      "Epoch 19/20, step 651/829, loss: 0.8973476886749268\n",
      "Epoch 19/20, step 661/829, loss: 0.5597435235977173\n",
      "Epoch 19/20, step 671/829, loss: 1.0758641958236694\n",
      "Epoch 19/20, step 681/829, loss: 1.3012933731079102\n",
      "Epoch 19/20, step 691/829, loss: 3.4225962162017822\n",
      "Epoch 19/20, step 701/829, loss: 0.9632776975631714\n",
      "Epoch 19/20, step 711/829, loss: 1.4156216382980347\n",
      "Epoch 19/20, step 721/829, loss: 0.7405089139938354\n",
      "Epoch 19/20, step 731/829, loss: 0.5132137537002563\n",
      "Epoch 19/20, step 741/829, loss: 1.4358125925064087\n",
      "Epoch 19/20, step 751/829, loss: 0.5016160011291504\n",
      "Epoch 19/20, step 761/829, loss: 1.9978361129760742\n",
      "Epoch 19/20, step 771/829, loss: 2.2048633098602295\n",
      "Epoch 19/20, step 781/829, loss: 1.2885948419570923\n",
      "Epoch 19/20, step 791/829, loss: 0.3347301781177521\n",
      "Epoch 19/20, step 801/829, loss: 0.659247875213623\n",
      "Epoch 19/20, step 811/829, loss: 0.7150958776473999\n",
      "Epoch 19/20, step 821/829, loss: 0.3967505991458893\n",
      "Epoch 20/20, step 1/829, loss: 1.568052887916565\n",
      "Epoch 20/20, step 11/829, loss: 0.30510711669921875\n",
      "Epoch 20/20, step 21/829, loss: 0.8542848229408264\n",
      "Epoch 20/20, step 31/829, loss: 1.3740086555480957\n",
      "Epoch 20/20, step 41/829, loss: 2.255211353302002\n",
      "Epoch 20/20, step 51/829, loss: 1.3011101484298706\n",
      "Epoch 20/20, step 61/829, loss: 0.7295741438865662\n",
      "Epoch 20/20, step 71/829, loss: 0.4530571699142456\n",
      "Epoch 20/20, step 81/829, loss: 0.1716446578502655\n",
      "Epoch 20/20, step 91/829, loss: 45.52566146850586\n",
      "Epoch 20/20, step 101/829, loss: 1.7600657939910889\n",
      "Epoch 20/20, step 111/829, loss: 1.2523859739303589\n",
      "Epoch 20/20, step 121/829, loss: 0.9401373863220215\n",
      "Epoch 20/20, step 131/829, loss: 0.7963032126426697\n",
      "Epoch 20/20, step 141/829, loss: 0.9427083134651184\n",
      "Epoch 20/20, step 151/829, loss: 1.330655813217163\n",
      "Epoch 20/20, step 161/829, loss: 2.3343865871429443\n",
      "Epoch 20/20, step 171/829, loss: 0.6874030232429504\n",
      "Epoch 20/20, step 181/829, loss: 1.139962077140808\n",
      "Epoch 20/20, step 191/829, loss: 0.4713888168334961\n",
      "Epoch 20/20, step 201/829, loss: 31.29662322998047\n",
      "Epoch 20/20, step 211/829, loss: 1.975845456123352\n",
      "Epoch 20/20, step 221/829, loss: 0.36844903230667114\n",
      "Epoch 20/20, step 231/829, loss: 31.644073486328125\n",
      "Epoch 20/20, step 241/829, loss: 0.8040888905525208\n",
      "Epoch 20/20, step 251/829, loss: 0.654534637928009\n",
      "Epoch 20/20, step 261/829, loss: 0.8078511357307434\n",
      "Epoch 20/20, step 271/829, loss: 0.9776390790939331\n",
      "Epoch 20/20, step 281/829, loss: 0.4922640323638916\n",
      "Epoch 20/20, step 291/829, loss: 0.8284755945205688\n",
      "Epoch 20/20, step 301/829, loss: 0.38346749544143677\n",
      "Epoch 20/20, step 311/829, loss: 0.7208978533744812\n",
      "Epoch 20/20, step 321/829, loss: 3.131484031677246\n",
      "Epoch 20/20, step 331/829, loss: 2.191923141479492\n",
      "Epoch 20/20, step 341/829, loss: 3.1409809589385986\n",
      "Epoch 20/20, step 351/829, loss: 0.8813291788101196\n",
      "Epoch 20/20, step 361/829, loss: 1.2572258710861206\n",
      "Epoch 20/20, step 371/829, loss: 2.953143835067749\n",
      "Epoch 20/20, step 381/829, loss: 0.878088653087616\n",
      "Epoch 20/20, step 391/829, loss: 0.6834089159965515\n",
      "Epoch 20/20, step 401/829, loss: 0.849740743637085\n",
      "Epoch 20/20, step 411/829, loss: 2.5116264820098877\n",
      "Epoch 20/20, step 421/829, loss: 1.8851139545440674\n",
      "Epoch 20/20, step 431/829, loss: 0.6060415506362915\n",
      "Epoch 20/20, step 441/829, loss: 0.8849648237228394\n",
      "Epoch 20/20, step 451/829, loss: 0.8526003956794739\n",
      "Epoch 20/20, step 461/829, loss: 0.4742746949195862\n",
      "Epoch 20/20, step 471/829, loss: 0.29169806838035583\n",
      "Epoch 20/20, step 481/829, loss: 4.826923370361328\n",
      "Epoch 20/20, step 491/829, loss: 0.7817510962486267\n",
      "Epoch 20/20, step 501/829, loss: 19.736799240112305\n",
      "Epoch 20/20, step 511/829, loss: 2.594099521636963\n",
      "Epoch 20/20, step 521/829, loss: 1.5518039464950562\n",
      "Epoch 20/20, step 531/829, loss: 1.3110904693603516\n",
      "Epoch 20/20, step 541/829, loss: 1.1047427654266357\n",
      "Epoch 20/20, step 551/829, loss: 1.249380111694336\n",
      "Epoch 20/20, step 561/829, loss: 2.0641820430755615\n",
      "Epoch 20/20, step 571/829, loss: 0.7882345914840698\n",
      "Epoch 20/20, step 581/829, loss: 1.2710964679718018\n",
      "Epoch 20/20, step 591/829, loss: 0.7658771872520447\n",
      "Epoch 20/20, step 601/829, loss: 1.6174248456954956\n",
      "Epoch 20/20, step 611/829, loss: 1.0937466621398926\n",
      "Epoch 20/20, step 621/829, loss: 0.9131677746772766\n",
      "Epoch 20/20, step 631/829, loss: 1.1976220607757568\n",
      "Epoch 20/20, step 641/829, loss: 0.45661765336990356\n",
      "Epoch 20/20, step 651/829, loss: 2.0336391925811768\n",
      "Epoch 20/20, step 661/829, loss: 2.815058469772339\n",
      "Epoch 20/20, step 671/829, loss: 11.25285816192627\n",
      "Epoch 20/20, step 681/829, loss: 1.5661885738372803\n",
      "Epoch 20/20, step 691/829, loss: 1.3034502267837524\n",
      "Epoch 20/20, step 701/829, loss: 2.3443593978881836\n",
      "Epoch 20/20, step 711/829, loss: 0.9115637540817261\n",
      "Epoch 20/20, step 721/829, loss: 0.7273086905479431\n",
      "Epoch 20/20, step 731/829, loss: 0.401574969291687\n",
      "Epoch 20/20, step 741/829, loss: 0.5899322032928467\n",
      "Epoch 20/20, step 751/829, loss: 0.3525896966457367\n",
      "Epoch 20/20, step 761/829, loss: 1.3810913562774658\n",
      "Epoch 20/20, step 771/829, loss: 0.3503335416316986\n",
      "Epoch 20/20, step 781/829, loss: 0.6551542282104492\n",
      "Epoch 20/20, step 791/829, loss: 1.3825256824493408\n",
      "Epoch 20/20, step 801/829, loss: 2.3445708751678467\n",
      "Epoch 20/20, step 811/829, loss: 1.1029915809631348\n",
      "Epoch 20/20, step 821/829, loss: 0.8009313344955444\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, step {i+1}/{len(train_loader)}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstat_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.stat_dict(), \"keypoints_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
